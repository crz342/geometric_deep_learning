{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#0.import and random seeds\n"
      ],
      "metadata": {
        "id": "O6G1rRnYt22w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WhlcLeoVsyWt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributions as td\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "#dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)                           # Python built-in random module\n",
        "    np.random.seed(seed)                        # NumPy random generator\n",
        "    torch.manual_seed(seed)                     # PyTorch CPU random seed\n",
        "    torch.cuda.manual_seed(seed)                # PyTorch current GPU random seed\n",
        "    torch.cuda.manual_seed_all(seed)            # PyTorch all GPUs random seed\n",
        "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior in cuDNN\n",
        "    torch.backends.cudnn.benchmark = False      # Disable auto-optimization to prevent non-deterministic behavior\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)    # Control hash-based randomness in Python\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "OtQ3OkKP1FyY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Dataset  \n",
        "just copy the code provided by the professor\n",
        "\n"
      ],
      "metadata": {
        "id": "4OuS5xx-nLi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subsample(data, targets, num_data, num_classes):\n",
        "    idx = targets < num_classes  # Select samples with class labels less than num_classes (e.g., only classes 0, 1, 2)\n",
        "    new_data = data[idx][:num_data].unsqueeze(1).to(torch.float32) / 255  # Select the first num_data images and normalize to [0,1]\n",
        "    new_targets = targets[idx][:num_data]  # Select corresponding labels for the subsampled images\n",
        "    return torch.utils.data.TensorDataset(new_data, new_targets)  # Create a TensorDataset with the filtered images and labels\n",
        "\n",
        "num_train_data = 2048\n",
        "num_classes = 3\n",
        "\n",
        "train_tensors = datasets.MNIST(\n",
        "    \"data/\", train=True, download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
        ")\n",
        "\n",
        "test_tensors = datasets.MNIST(\n",
        "    \"data/\", train=False, download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
        ")\n",
        "train_data = subsample(\n",
        "    train_tensors.data, train_tensors.targets,\n",
        "    num_train_data, num_classes\n",
        ")\n",
        "test_data = subsample(\n",
        "    test_tensors.data, test_tensors.targets,\n",
        "    num_train_data, num_classes\n",
        ")\n",
        "\n",
        "batch_size=32\n",
        "mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "mnist_test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "latent_dim=2\n",
        "M=latent_dim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "1ul7SutXjtmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93114da3-0904-4521-dfc2-e21e99ec0fca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 41.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.16MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.7MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.74MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.GaussianPrior and Encoder/Decoder\n",
        "Just copy the code provided by the professor\n"
      ],
      "metadata": {
        "id": "RKGEA5qGnR4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianPrior(nn.Module):\n",
        "    def __init__(self, M):\n",
        "        \"\"\"\n",
        "        Define a Gaussian prior distribution with zero mean and unit variance.\n",
        "\n",
        "                Parameters:\n",
        "        M: [int]\n",
        "           Dimension of the latent space.\n",
        "        \"\"\"\n",
        "        super(GaussianPrior, self).__init__()\n",
        "        self.M = M\n",
        "        self.mean = nn.Parameter(torch.zeros(self.M), requires_grad=False)\n",
        "        self.std = nn.Parameter(torch.ones(self.M), requires_grad=False)\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        Return the prior distribution.\n",
        "\n",
        "        Returns:\n",
        "        prior: [torch.distributions.Distribution]\n",
        "        \"\"\"\n",
        "        return td.Independent(td.Normal(loc=self.mean, scale=self.std), 1)\n",
        "\n",
        "class GaussianEncoder(nn.Module):\n",
        "    def __init__(self, encoder_net):\n",
        "        \"\"\"\n",
        "        Define a Gaussian encoder distribution based on a given encoder network.\n",
        "\n",
        "        Parameters:\n",
        "        encoder_net: [torch.nn.Module]\n",
        "            The encoder network that takes a tensor of dimension\n",
        "            `(batch_size, feature_dim1, feature_dim2)` as input\n",
        "            and outputs a tensor of dimension `(batch_size, 2M)`,\n",
        "            where M is the dimension of the latent space.\n",
        "        \"\"\"\n",
        "        super(GaussianEncoder, self).__init__()\n",
        "        self.encoder_net = encoder_net\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Given a batch of input data, return a Gaussian distribution over the latent space.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            A tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
        "\n",
        "        Returns:\n",
        "        A Gaussian distribution with computed mean and standard deviation.\n",
        "        \"\"\"\n",
        "        mean, std = torch.chunk(self.encoder_net(x), 2, dim=-1)\n",
        "        return td.Independent(td.Normal(loc=mean, scale=torch.exp(std)), 1)\n",
        "\n",
        "        # Example:\n",
        "        # z = torch.randn(4, 10)  # Assume z is a tensor of shape [batch_size=4, 10]\n",
        "        # a, b = torch.chunk(z, 2, dim=-1)\n",
        "        # a and b will have shape [4, 5], as the tensor is split into two parts along the last dimension.\n",
        "def new_encoder():\n",
        "        encoder_net = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 2 * M),\n",
        "        )\n",
        "        return encoder_net\n",
        "class GaussianDecoder(nn.Module):\n",
        "    def __init__(self, decoder_net):\n",
        "        \"\"\"\n",
        "        Define a Gaussian decoder distribution based on a given decoder network.\n",
        "\n",
        "        Parameters:\n",
        "        decoder_net: [torch.nn.Module]\n",
        "            The decoder network that takes a tensor of dimension `(batch_size, M)`\n",
        "            as input, where M is the dimension of the latent space, and outputs a\n",
        "            tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
        "        \"\"\"\n",
        "        super(GaussianDecoder, self).__init__()\n",
        "        self.decoder_net = decoder_net\n",
        "        # self.std = nn.Parameter(torch.ones(28, 28) * 0.5, requires_grad=True)\n",
        "        # In case you want to learn the standard deviation of the Gaussian.\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Given a batch of latent variables, return a Gaussian distribution over the data space.\n",
        "\n",
        "        Parameters:\n",
        "        z: [torch.Tensor]\n",
        "            A tensor of dimension `(batch_size, M)`, where M is the dimension of the latent space.\n",
        "\n",
        "        Returns:\n",
        "        A Gaussian distribution with computed mean and a fixed standard deviation.\n",
        "        \"\"\"\n",
        "        means = self.decoder_net(z)\n",
        "        return td.Independent(td.Normal(loc=means, scale=1e-1), 3) #note the variance of decoder is fixed\n",
        "        # This defines a 784-dimensional independent normal distribution, where each dimension is independent.\n",
        "def new_decoder():\n",
        "        decoder_net = nn.Sequential(\n",
        "            nn.Linear(M, 512),\n",
        "            nn.Unflatten(-1, (32, 4, 4)),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=0),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "        return decoder_net"
      ],
      "metadata": {
        "id": "4Ewa8X8LuVcS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.VAE\n",
        "having changed the provided code ,so that for each mini-batch of data, we randomly sample a decoder and take a gradient step to optimize the ELBO\n"
      ],
      "metadata": {
        "id": "G3nNIR4xoM5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, prior, decoders, encoder):\n",
        "        \"\"\"\n",
        "        Variational Autoencoder (VAE) with multiple decoders.\n",
        "\n",
        "        Parameters:\n",
        "        prior: [torch.nn.Module]\n",
        "            The prior distribution over the latent space.\n",
        "        decoders: [list of torch.nn.Module]\n",
        "            A list containing multiple decoders.\n",
        "        encoder: [torch.nn.Module]\n",
        "            The encoder network that maps input data to a latent distribution.\n",
        "        \"\"\"\n",
        "        super(VAE, self).__init__()\n",
        "        self.prior = prior\n",
        "        self.decoders = nn.ModuleList(decoders)  # Use ModuleList to allow PyTorch to properly track parameters\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def elbo(self, x, decoder_idx):\n",
        "        \"\"\"\n",
        "        Compute the Evidence Lower Bound (ELBO) for a given input and selected decoder.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            The input data tensor.\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "\n",
        "        Returns:\n",
        "        The computed ELBO value.\n",
        "        \"\"\"\n",
        "        q = self.encoder(x)  # Encode input into a latent distribution\n",
        "        z = q.rsample()  # Sample from the latent distribution using the reparameterization trick\n",
        "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
        "\n",
        "        elbo = torch.mean(\n",
        "            decoder(z).log_prob(x) - q.log_prob(z) + self.prior().log_prob(z)\n",
        "        )  # Compute ELBO using the likelihood, posterior, and prior\n",
        "\n",
        "        return elbo\n",
        "\n",
        "    def sample(self, decoder_idx, n_samples=1):\n",
        "        \"\"\"\n",
        "        Generate samples from the specified decoder.\n",
        "\n",
        "        Parameters:\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "        n_samples: [int, default=1]\n",
        "            The number of samples to generate.\n",
        "\n",
        "        Returns:\n",
        "        A batch of generated samples.\n",
        "        \"\"\"\n",
        "        z = self.prior().sample(torch.Size([n_samples]))  # Sample from the prior distribution\n",
        "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
        "        return decoder(z).sample()  # Generate samples from the decoder\n",
        "\n",
        "    def forward(self, x, decoder_idx):\n",
        "        \"\"\"\n",
        "        Compute the negative ELBO for optimization.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            The input data tensor.\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "\n",
        "        Returns:\n",
        "        The negative ELBO value.\n",
        "        \"\"\"\n",
        "        return -self.elbo(x, decoder_idx)\n"
      ],
      "metadata": {
        "id": "qKI-kp2_2Kaj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Training vae\n"
      ],
      "metadata": {
        "id": "BGBEs4iMoT4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizers, data_loader, epochs, device):\n",
        "    num_decoders = len(model.decoders)\n",
        "    #one error\n",
        "    # have changed the code to fit with different number of decoders\n",
        "    total_epochs = epochs_per_decoder * num_decoders\n",
        "    num_steps = len(data_loader) * total_epochs\n",
        "    epoch = 0\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    def noise(x, std=0.05):\n",
        "        eps = std * torch.randn_like(x)\n",
        "        return torch.clamp(x + eps, min=0.0, max=1.0)\n",
        "\n",
        "    with tqdm(range(num_steps)) as pbar:\n",
        "        for step in pbar:\n",
        "            try:\n",
        "                x = next(iter(data_loader))[0]\n",
        "                x = noise(x.to(device))\n",
        "                model=model\n",
        "                idx = torch.randint(0, num_decoders, (1,)).item() #for each mini-batch of data, we randomly sample a decoder and take a gradient step to optimize the ELBO\n",
        "                optimizer = optimizers[idx]\n",
        "                optimizer.zero_grad()\n",
        "                loss = model(x, decoder_idx=idx) #correspond to the changed part in VAE\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                loss_val = loss.detach().cpu().item()\n",
        "                losses.append(loss_val)\n",
        "\n",
        "                if step % 5 == 0:\n",
        "                    pbar.set_description(\n",
        "                        f\"epoch={epoch}, step={step}, decoder={idx}, loss={loss_val:.1f}\"\n",
        "                    )\n",
        "                if (step + 1) % len(data_loader) == 0:\n",
        "                    epoch += 1\n",
        "            except KeyboardInterrupt:\n",
        "                print(f\"Stopped at epoch {epoch}, step {step}, loss {loss_val:.1f}\")\n",
        "                break\n",
        "\n",
        "    return losses\n"
      ],
      "metadata": {
        "id": "ORvNA3H97nNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#because in part B we need 10 independent VAEs with  decoders 1,2,3, so I define a new train function\n",
        "#S is the number of the decoders\n",
        "def train_single_vae(seed, save_path, S, epochs_per_decoder):\n",
        "    set_seed(seed)\n",
        "    decoders = [GaussianDecoder(new_decoder()) for _ in range(S)]\n",
        "    #instantiating  S randomly initialized decoders\n",
        "    # note: set_seed(1001) only ensure the next time we run set_seed(1001), it's still the SAME randomly three decoders\n",
        "    # it will not destroy of the randomness of three different decoders\n",
        "    encoder = GaussianEncoder(new_encoder())\n",
        "    prior = GaussianPrior(M)\n",
        "\n",
        "    model = VAE(prior, decoders, encoder).to(device)\n",
        "   # I just use the learning rate provided\n",
        "    optimizers = [\n",
        "        torch.optim.Adam(\n",
        "            list(model.encoder.parameters()) + list(decoder.parameters()), lr=1e-3\n",
        "        )\n",
        "        for decoder in model.decoders\n",
        "    ]\n",
        "\n",
        "    losses = train(model, optimizers, mnist_train_loader, epochs_per_decoder, device)\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    plt.figure()\n",
        "    plt.plot(range(5000, len(losses)), losses[5000:])\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"ELBO Loss\")\n",
        "    plt.title(f\"Training Loss (Seed {seed}) [After 5000 Steps]\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path.replace(\".pt\", \"_loss.png\"))\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "DAYjbcQ05-xL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 train ONE VAE single and ensemble"
      ],
      "metadata": {
        "id": "WcUldcuA2MxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# General training parameters\n",
        "epochs_per_decoder = 400 # in fact, If I use 300,400 total epochs for 3-decoder vae, the peformance is not well\n",
        "seed_base = 1000\n",
        "\n",
        "# Single decoder model\n",
        "num_decoders_single = 1\n",
        "experiments_folder_single = \"experiments/vae_single\"\n",
        "os.makedirs(experiments_folder_single, exist_ok=True)  # Create directory if it doesn't exist\n",
        "\n",
        "# Multiple decoder model\n",
        "num_decoders_ensemble = 3\n",
        "experiments_folder_ensemble = \"experiments/vae_ensemble\"\n",
        "os.makedirs(experiments_folder_ensemble, exist_ok=True)  # Create directory if it doesn't exist"
      ],
      "metadata": {
        "id": "thxtKogl6GGG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train single decoder model\n",
        "for i in range(1):  # Can be expanded to train multiple VAE models,see another file.\n",
        "    seed = seed_base + i\n",
        "    save_path = f\"{experiments_folder_single}/sinmodel_seed{seed}.pt\"\n",
        "    print(f\"Training SINGLE model with seed {seed}...\")\n",
        "    train_single_vae(seed, save_path, num_decoders_single, epochs_per_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMUX6PRlYsmd",
        "outputId": "a4a87157-aa16-4974-9d82-45b9f948233c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SINGLE model with seed 1000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25600 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "epoch=399, step=25595, decoder=0, loss=37.4: 100%|██████████| 25600/25600 [03:06<00:00, 137.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ensemble decoder model one vae\n",
        "for i in range(1):  # Can be expanded to train multiple models\n",
        "    seed = seed_base + i\n",
        "    save_path = f\"{experiments_folder_ensemble}/enmodel_seed{seed}.pt\"\n",
        "    print(f\"Training ENSEMBLE model with seed {seed}...\")\n",
        "    train_single_vae(seed, save_path, num_decoders_ensemble, epochs_per_decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVNfwkEBkewT",
        "outputId": "618696e1-fb73-47d2-afc8-ceb238cc696a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ENSEMBLE model with seed 1000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=1199, step=76795, decoder=2, loss=-127.0: 100%|██████████| 76800/76800 [09:17<00:00, 137.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training download the model_seed.pt, next time directly load the model\n",
        "# Parameters\n",
        "M = latent_dim\n",
        "num_classes = 3\n",
        "seed = 1000\n",
        "# Load single decoder model\n",
        "decoders_single = [GaussianDecoder(new_decoder())]\n",
        "encoder_single = GaussianEncoder(new_encoder())\n",
        "prior_single = GaussianPrior(M)\n",
        "vae_single = VAE(prior_single, decoders_single, encoder_single).to(device)\n",
        "vae_single.load_state_dict(torch.load(f\"{experiments_folder_single}/sinmodel_seed{seed}.pt\"))\n",
        "# Load multiple decoder model\n",
        "decoders_ensemble = [GaussianDecoder(new_decoder()) for _ in range(num_decoders_ensemble)]\n",
        "encoder_ensemble = GaussianEncoder(new_encoder())\n",
        "prior_ensemble = GaussianPrior(M)\n",
        "vae_ensemble = VAE(prior_ensemble, decoders_ensemble, encoder_ensemble).to(device)\n",
        "vae_ensemble.load_state_dict(torch.load(f\"{experiments_folder_ensemble}/enmodel_seed{seed}.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps_jve53nDOX",
        "outputId": "4bd21f2e-1102-4f01-b25e-87f028febf60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.1 latent space:\n",
        "not relevant, just for checking whether the model encode the right latent space"
      ],
      "metadata": {
        "id": "TSCKksdsmKdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_latent_space(model, dataloader, num_classes, save_path):\n",
        "    model.eval()\n",
        "    zs, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            z = model.encoder(x).base_dist.loc\n",
        "            zs.append(z.cpu())\n",
        "            labels.append(y)\n",
        "    zs = torch.cat(zs, dim=0).numpy()\n",
        "    labels = torch.cat(labels, dim=0).numpy()\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    for i in range(num_classes):\n",
        "        idx = labels == i\n",
        "        plt.scatter(zs[idx, 0], zs[idx, 1], s=5, alpha=0.6, label=f\"Class {i}\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Latent Space\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "j1qxt-EBsYcv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualize the latent space for the single decoder model\n",
        "visualize_latent_space(\n",
        "    vae_single,\n",
        "    mnist_test_loader,\n",
        "    num_classes=num_classes,\n",
        "    save_path=\"latent_space_single.png\"\n",
        ")\n",
        "\n",
        "# Visualize the latent space for the multiple decoder model\n",
        "visualize_latent_space(\n",
        "    vae_ensemble,\n",
        "    mnist_test_loader,\n",
        "    num_classes=num_classes,\n",
        "    save_path=\"latent_space_ensemble.png\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "XRKEVNIIsbOi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2 sample\n",
        "not relevant to this task, just for checking the quality of VAE\n"
      ],
      "metadata": {
        "id": "qYydvSnInuB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiments_single = \"experiments/vae_single\"\n",
        "outputs_single = \"experiments/vae_single_outputs\"\n",
        "os.makedirs(outputs_single, exist_ok=True)  # Create output directory if it doesn't exist\n",
        "vae_single.eval()  # Set model to evaluation mode\n",
        "out_dir_single = f\"{outputs_single}/vae_seed{seed}\"\n",
        "os.makedirs(out_dir_single, exist_ok=True)  # Create output directory for the specific seed\n",
        "with torch.no_grad():\n",
        "    # Sampling (only one decoder)\n",
        "    samples = vae_single.sample(decoder_idx=0, n_samples=64).cpu()\n",
        "    save_image(samples.view(64, 1, 28, 28), f\"{out_dir_single}/samples_decoder0.png\")\n",
        "\n",
        "    # Reconstruction\n",
        "    data = next(iter(mnist_test_loader))[0].to(device)  # Get a batch of test data\n",
        "    z = vae_single.encoder(data).mean  # Encode data into latent space\n",
        "    recon = vae_single.decoders[0](z).mean  # Decode from latent representation\n",
        "    save_image(\n",
        "        torch.cat([data.cpu(), recon.cpu()], dim=0),  # Concatenate original and reconstructed images\n",
        "        f\"{out_dir_single}/reconstruction_decoder0.png\"\n",
        "    )"
      ],
      "metadata": {
        "id": "8m9fnm5dukRX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoders=3\n",
        "outputs_ensemble = \"experiments/vae_ensemble_outputs\"\n",
        "os.makedirs(outputs_ensemble, exist_ok=True)  # Create output directory if it doesn't exist\n",
        "vae_ensemble.eval()  # Set model to evaluation mode\n",
        "# Load multiple decoder model\n",
        "out_dir_ensemble = f\"{outputs_ensemble}/vae_seed{seed}\"\n",
        "os.makedirs(out_dir_ensemble, exist_ok=True)  # Create output directory for the specific seed\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Sampling from each decoder\n",
        "    for i in range(num_decoders):\n",
        "        samples = vae_ensemble.sample(decoder_idx=i, n_samples=64).cpu()\n",
        "        save_image(samples.view(64, 1, 28, 28), f\"{out_dir_ensemble}/samples_decoder{i}.png\")\n",
        "\n",
        "    # Reconstruction using each decoder\n",
        "    data = next(iter(mnist_test_loader))[0].to(device)  # Get a batch of test data\n",
        "    z = vae_ensemble.encoder(data).mean  # Encode data into latent space\n",
        "    for i in range(num_decoders):\n",
        "        recon = vae_ensemble.decoders[i](z).mean  # Decode from latent representation\n",
        "        save_image(\n",
        "            torch.cat([data.cpu(), recon.cpu()], dim=0),  # Concatenate original and reconstructed images\n",
        "            f\"{out_dir_ensemble}/reconstruction_decoder{i}.png\"\n",
        "        )\n"
      ],
      "metadata": {
        "id": "NhfTtVxourQg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3 elbo not relevant to this task\n"
      ],
      "metadata": {
        "id": "ZsfgWdGVsNBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "num_vaes =1\n",
        "experiments_folder = \"experiments/vae_retrain_seeds\"\n",
        "\n",
        "for vae_idx in range(num_vaes):\n",
        "    seed = 1000 + vae_idx\n",
        "    model_path = f\"{experiments_folder}/model_seed{seed}.pt\"\n",
        "\n",
        "\n",
        "    decoders = [GaussianDecoder(new_decoder()) for _ in range(num_decoders)]\n",
        "    encoder = GaussianEncoder(new_encoder())\n",
        "    prior = GaussianPrior(M)\n",
        "\n",
        "    model = VAE(prior, decoders, encoder).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    elbos_per_decoder = [[] for _ in range(num_decoders)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, _ in mnist_test_loader:\n",
        "            x = x.to(device)\n",
        "            for i in range(num_decoders):\n",
        "                elbo = model.elbo(x, decoder_idx=i)\n",
        "                elbos_per_decoder[i].append(elbo)\n",
        "\n",
        "\n",
        "    print(f\"\\nVAE model with seed {seed}:\")\n",
        "    for i in range(num_decoders):\n",
        "        mean_elbo = torch.tensor(elbos_per_decoder[i]).mean()\n",
        "        print(f\"  Decoder {i} mean test ELBO: {mean_elbo.item():.4f}\")\n",
        "'''\n"
      ],
      "metadata": {
        "id": "sPMF4FLSty75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "4a8f6f3e-0cb8-49f3-a3d0-1a561051b2b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnum_vaes =1\\nexperiments_folder = \"experiments/vae_retrain_seeds\"\\n\\nfor vae_idx in range(num_vaes):\\n    seed = 1000 + vae_idx\\n    model_path = f\"{experiments_folder}/model_seed{seed}.pt\"\\n\\n\\n    decoders = [GaussianDecoder(new_decoder()) for _ in range(num_decoders)]\\n    encoder = GaussianEncoder(new_encoder())\\n    prior = GaussianPrior(M)\\n\\n    model = VAE(prior, decoders, encoder).to(device)\\n    model.load_state_dict(torch.load(model_path, map_location=device))\\n    model.eval()\\n\\n    elbos_per_decoder = [[] for _ in range(num_decoders)]\\n\\n    with torch.no_grad():\\n        for x, _ in mnist_test_loader:\\n            x = x.to(device)\\n            for i in range(num_decoders):\\n                elbo = model.elbo(x, decoder_idx=i)\\n                elbos_per_decoder[i].append(elbo)\\n\\n\\n    print(f\"\\nVAE model with seed {seed}:\")\\n    for i in range(num_decoders):\\n        mean_elbo = torch.tensor(elbos_per_decoder[i]).mean()\\n        print(f\"  Decoder {i} mean test ELBO: {mean_elbo.item():.4f}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 cruve and energy\n"
      ],
      "metadata": {
        "id": "Z7_VxVHhFZzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.1 cubiccurve\n"
      ],
      "metadata": {
        "id": "j_8WxRNksmWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#correspond to page 69 in our textbook\n",
        "class CubicCurve(nn.Module):\n",
        "    def __init__(self, c0, c1):\n",
        "        \"\"\"\n",
        "        Cubic polynomial curve module with fixed endpoints and parameterized middle section.\n",
        "\n",
        "        Parameters:\n",
        "        - c0: [d] Tensor representing the start point.\n",
        "        - c1: [d] Tensor representing the end point.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"c0\", c0)\n",
        "        self.register_buffer(\"c1\", c1)\n",
        "\n",
        "        d = c0.shape[0]\n",
        "        # Learnable parameters: w1, w2 ∈ R^d\n",
        "        self.w1 = nn.Parameter(torch.zeros(d, requires_grad=True))\n",
        "        self.w2 = nn.Parameter(torch.zeros(d, requires_grad=True))\n",
        "\n",
        "    def forward(self, t):\n",
        "        \"\"\"\n",
        "        Forward pass to compute the cubic curve.\n",
        "\n",
        "        Parameters:\n",
        "        - t: [B] or [B, 1], curve parameter t ∈ [0, 1].\n",
        "\n",
        "        Returns:\n",
        "        - c(t): [B, d], computed points on the cubic curve.\n",
        "        \"\"\"\n",
        "        if t.dim() == 1:\n",
        "            t = t.unsqueeze(1)  # Reshape to [B, 1],so that t can * c0\n",
        "\n",
        "        # [B, d] broadcasting\n",
        "        t1 = t\n",
        "        t2 = t ** 2\n",
        "        t3 = t ** 3\n",
        "\n",
        "        w1 = self.w1  # [d]\n",
        "        w2 = self.w2  # [d]\n",
        "        w3 = -w1 - w2  # Ensure smooth transition\n",
        "\n",
        "        # Linear interpolation between c0 and c1\n",
        "        linear = (1 - t) * self.c0 + t * self.c1  # [B, d]\n",
        "\n",
        "        # Residual polynomial component\n",
        "        residual = w1 * t1 + w2 * t2 + w3 * t3  # [B, d]\n",
        "\n",
        "        return linear + residual  # [B, d], final cubic curve output\n"
      ],
      "metadata": {
        "id": "V7r1Tut2FzsN"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 compute_energy\n",
        "\n",
        "$$\n",
        "\\mathcal{E}[\\gamma] \\approx \\sum_{t=0}^{T-1} \\mathbb{E}_{\\theta, \\theta' \\sim q(\\theta) q(\\theta)}\n",
        "\\left[ \\left\\| f_{\\theta} (\\gamma(t + \\frac{1}{T})) - f_{\\theta'} (\\gamma(t / T)) \\right\\|^2 \\right]\n",
        "$$\n",
        "\n",
        "$f_{\\theta}$ $f_{\\theta'}$ denotes deoder ensemble members drawn uniformly"
      ],
      "metadata": {
        "id": "FuBRA6srsq2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def compute_curve_energy(curve, decoders, T=16, num_samples=1, fixed_indices=None, device='cuda'):\n",
        "    \"\"\"\n",
        "    Compute the energy of a curve using fixed decoder indices to ensure the objective function remains consistent.\n",
        "\n",
        "    Parameters:\n",
        "    - curve: An instance of CubicCurve\n",
        "    - decoders: List of decoder modules\n",
        "    - T: Number of time steps, default is 16\n",
        "    - num_samples: Number of Monte Carlo samples, default is 1\n",
        "    - fixed_indices: Pre-fixed decoder indices [(idx1_t0, idx2_t0), (idx1_t1, idx2_t1), ...]\n",
        "    - device: Computing device, default is 'cuda'\n",
        "\n",
        "    Returns:\n",
        "    - Scalar energy value\n",
        "    \"\"\"\n",
        "    total_energy = 0.0  # Accumulate energy over all time steps\n",
        "\n",
        "    for i in range(T):\n",
        "        t0 = torch.tensor([i / T], device=device, dtype=torch.float32)\n",
        "        t1 = torch.tensor([(i + 1) / T], device=device, dtype=torch.float32)\n",
        "\n",
        "        x0 = curve(t0)  # γ(t0), shape [1, d]\n",
        "        x1 = curve(t1)  # γ(t1)\n",
        "\n",
        "        energy = 0.0  # Energy for the current time step\n",
        "\n",
        "        for _ in range(num_samples):\n",
        "            idx1, idx2 = fixed_indices[i]  # Retrieve fixed indices\n",
        "\n",
        "            # **Compute only the required decoder outputs**\n",
        "            sampled_mean_x0 = decoders[idx1](x0).mean  # Directly compute the mean for idx1\n",
        "            sampled_mean_x1 = decoders[idx2](x1).mean  # Directly compute the mean for idx2\n",
        "\n",
        "            # Compute L2 norm\n",
        "            energy += torch.norm(sampled_mean_x1 - sampled_mean_x0, p=2)\n",
        "\n",
        "        # Take Monte Carlo average, negligible when num_samples = 1\n",
        "        total_energy += energy / num_samples\n",
        "\n",
        "    return total_energy  # Return total energy\n"
      ],
      "metadata": {
        "id": "L1ntkmnPoo0g"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.3 optimize_geodesics"
      ],
      "metadata": {
        "id": "6e6UxF2PO3Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_geodesic(c0, c1, decoders, T=16, steps=500, lr=1e-2, device='cuda',\n",
        "                      early_stopping_n=100, early_stopping_delta=1e-4):\n",
        "    \"\"\"\n",
        "    Optimize a geodesic curve while ensuring the objective function remains unchanged during optimization.\n",
        "\n",
        "    Parameters:\n",
        "    - c0: Starting point\n",
        "    - c1: Endpoint\n",
        "    - decoders: List of decoder modules\n",
        "    - T: Number of time steps\n",
        "    - steps: Number of optimization iterations\n",
        "    - lr: Learning rate\n",
        "    - device: Computing device\n",
        "    - early_stopping_n: Number of steps to check for early stopping\n",
        "    - early_stopping_delta: Minimum required improvement to continue\n",
        "\n",
        "    Returns:\n",
        "    - Optimized curve\n",
        "    - Logged energy values\n",
        "    \"\"\"\n",
        "    curve = CubicCurve(c0, c1).to(device)  # Initialize the curve\n",
        "    optimizer = torch.optim.Adam(curve.parameters(), lr=lr)  # Adam optimizer\n",
        "    energy_log = []  # Store energy values\n",
        "\n",
        "    # **Pre-generate fixed decoder indices**\n",
        "    fixed_indices = [(torch.randint(0, len(decoders), (1,), device=device).item(),\n",
        "                      torch.randint(0, len(decoders), (1,), device=device).item())\n",
        "                     for _ in range(T)]\n",
        "\n",
        "    best_energy = float('inf')\n",
        "    no_improve_count = 0  # Counter for early stopping\n",
        "\n",
        "    with tqdm(range(steps)) as pbar:\n",
        "        for step in pbar:\n",
        "            optimizer.zero_grad()  # Clear gradients\n",
        "            energy = compute_curve_energy(curve, decoders, T=T, fixed_indices=fixed_indices, device=device)  # Compute energy\n",
        "            energy.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update parameters\n",
        "\n",
        "            energy_value = energy.item()\n",
        "            energy_log.append(energy_value)  # Store energy value\n",
        "\n",
        "            # Early Stopping Logic\n",
        "            if energy_value < best_energy - early_stopping_delta:\n",
        "                best_energy = energy_value\n",
        "                no_improve_count = 0  # Reset counter\n",
        "            else:\n",
        "                no_improve_count += 1\n",
        "\n",
        "            if no_improve_count >= early_stopping_n:\n",
        "                print(f\"Early stopping at step {step}, energy: {energy_value:.6f}\")\n",
        "                break  # Stop training if no improvement\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_description(f\"Energy: {energy_value:.6f}\")\n",
        "\n",
        "    return curve, energy_log\n"
      ],
      "metadata": {
        "id": "JqEQ2nKLotZb"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.plot  25 random latent_varibale pairs\n"
      ],
      "metadata": {
        "id": "LE52pKwas5TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.1 data preparation"
      ],
      "metadata": {
        "id": "uKh_3_IruXFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#参数设置\n",
        "# ====== 参数设置 ======\n",
        "num_pairs = 25  # 需要处理的点对数量\n",
        "T = 256  # 测地线离散化段数\n",
        "steps = 4200  # 迭代步数\n",
        "lr = 1e-2  # 学习率\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "\n",
        "# 存储路径\n",
        "save_dir = \"energy/\"\n",
        "results_dir = \"results\"\n",
        "energy_dir = \"energy_logs\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "os.makedirs(energy_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "XYIsP4GQYt57"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Obtain Full Test Set Latent Representations (for Scatter Plot) ======\n",
        "def encode_all_test_latents(model):\n",
        "    \"\"\"\n",
        "    Encode the entire test dataset into the latent space.\n",
        "\n",
        "    Parameters:\n",
        "    - model: VAE model (single or ensemble) used for encoding.\n",
        "\n",
        "    Returns:\n",
        "    - zs: Tensor of latent representations.\n",
        "    - ys: Corresponding labels.\n",
        "    \"\"\"\n",
        "    zs, ys = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in mnist_test_loader:\n",
        "            x = x.to(device)\n",
        "            q = model.encoder(x)\n",
        "            z = q.base_dist.loc  # Extract mean of the latent distribution\n",
        "            zs.append(z.cpu())\n",
        "            ys.append(y)\n",
        "    return torch.cat(zs, dim=0), torch.cat(ys, dim=0)\n",
        "\n",
        "# Encode the test set using both models\n",
        "latent_z_single, labels_single = encode_all_test_latents(vae_single)\n",
        "latent_z_ensemble, labels_ensemble = encode_all_test_latents(vae_ensemble)"
      ],
      "metadata": {
        "id": "ObzRWc_gVHnD"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 每次计算完一个点对，就画 energy 和 geodesics 图\n",
        "def plot_energy_log_single(log, pair_idx, decoder_count):\n",
        "    folder = os.path.join(energy_dir, f\"vae_d{decoder_count}\")\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(log)\n",
        "    plt.xlabel(\"Optimization Step\")\n",
        "    plt.ylabel(\"Energy\")\n",
        "    plt.title(f\"Geodesic Energy (Decoder={decoder_count}, Pair={pair_idx})\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(folder, f\"pair_{pair_idx}.png\")\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "4rTFBHY-Sl6R"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_geodesics_progress(latent_z, labels, z_pairs, curves, decoder_count, pair_idx):\n",
        "    \"\"\"\n",
        "    累积绘制测地线路径，并叠加潜在变量空间（背景）。\n",
        "\n",
        "    Parameters:\n",
        "    - latent_z: 测试集潜在表示（背景散点）\n",
        "    - labels: 对应的类别标签（背景散点颜色）\n",
        "    - z_pairs: 累计的起始点对\n",
        "    - curves: 累计的测地线曲线\n",
        "    - decoder_count: 解码器数量\n",
        "    - pair_idx: 当前点对索引\n",
        "    \"\"\"\n",
        "    folder = os.path.join(results_dir, f\"vae_d{decoder_count}\")\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # 背景散点图，使用原来的 tab10 配色\n",
        "    scatter = plt.scatter(latent_z[:, 0], latent_z[:, 1], c=labels, cmap=\"tab10\", s=8, alpha=0.4)\n",
        "\n",
        "    t_vals = torch.linspace(0, 1, sample_steps).unsqueeze(1).to(device)\n",
        "\n",
        "    for i in range(len(curves)):\n",
        "        gamma = curves[i](t_vals).detach().cpu()\n",
        "        c0, c1 = z_pairs[i, 0].cpu(), z_pairs[i, 1].cpu()\n",
        "\n",
        "        # 不指定颜色，自动配色 + 线加粗\n",
        "        plt.plot(gamma[:, 0], gamma[:, 1], linewidth=2.2)  # 更粗线条\n",
        "        plt.plot([c0[0], c1[0]], [c0[1], c1[1]], 'k--', linewidth=1.0)  # 虚线连接端点\n",
        "\n",
        "    plt.title(f\"Geodesics (Decoder={decoder_count}, Pairs=1~{pair_idx+1})\")\n",
        "    plt.xlabel(\"z1\")\n",
        "    plt.ylabel(\"z2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(*scatter.legend_elements(), title=\"Class\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(folder, f\"geodesics_pairs_{pair_idx+1}.png\")\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "g746FHuMVRyF"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.2 load data and encode into latent  space z"
      ],
      "metadata": {
        "id": "xxotGtuLZp87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 读取测试数据 ======\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for x, y in mnist_test_loader:\n",
        "    test_images.append(x)\n",
        "    test_labels.append(y)\n",
        "\n",
        "test_images = torch.cat(test_images, dim=0)  # [N, 1, 28, 28]\n",
        "test_labels = torch.cat(test_labels, dim=0)\n",
        "\n",
        "# ====== 读取或生成固定的测试点对索引 ======\n",
        "index_file = os.path.join(save_dir, \"test_indices.pt\")\n",
        "if os.path.exists(index_file):\n",
        "    indices = torch.load(index_file)\n",
        "    print(f\"加载已有测试点对索引，共 {len(indices)//2} 对\")\n",
        "else:\n",
        "    N = test_images.shape[0]\n",
        "    indices = random.sample(range(N), 2 * num_pairs)\n",
        "    torch.save(indices, index_file)\n",
        "    print(f\"生成并保存新测试点对索引，共 {num_pairs} 对\")\n",
        "\n",
        "# ====== 生成固定的测试点对 ======\n",
        "x_pairs = torch.stack([\n",
        "    torch.stack([test_images[indices[i]], test_images[indices[i + 1]]], dim=0)\n",
        "    for i in range(0, 2 * num_pairs, 2)\n",
        "])  # Shape: [num_pairs, 2, 1, 28, 28]\n",
        "\n",
        "# ====== 进入 VAE 潜在空间 ======\n",
        "vae_single.eval()\n",
        "vae_ensemble.eval()\n",
        "\n",
        "z_pairs_single = []\n",
        "z_pairs_ensemble = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(num_pairs):\n",
        "        x0 = x_pairs[i, 0].to(device)  # 第一张图片\n",
        "        x1 = x_pairs[i, 1].to(device)  # 第二张图片\n",
        "\n",
        "        # 单解码器 VAE\n",
        "        z0_single = vae_single.encoder(x0.unsqueeze(0)).base_dist.loc.squeeze(0)\n",
        "        z1_single = vae_single.encoder(x1.unsqueeze(0)).base_dist.loc.squeeze(0)\n",
        "        z_pairs_single.append(torch.stack([z0_single, z1_single], dim=0))\n",
        "\n",
        "        # 多解码器 VAE\n",
        "        z0_ens = vae_ensemble.encoder(x0.unsqueeze(0)).base_dist.loc.squeeze(0)\n",
        "        z1_ens = vae_ensemble.encoder(x1.unsqueeze(0)).base_dist.loc.squeeze(0)\n",
        "        z_pairs_ensemble.append(torch.stack([z0_ens, z1_ens], dim=0))\n",
        "\n",
        "z_pairs_single = torch.stack(z_pairs_single)     # Shape: [num_pairs, 2, latent_dim]\n",
        "z_pairs_ensemble = torch.stack(z_pairs_ensemble) # Shape: [num_pairs, 2, latent_dim]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxGx_UWnSwXh",
        "outputId": "b6085904-6a6a-4ab6-d3c0-ce1610e4f437"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成并保存新测试点对索引，共 25 对\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 compute geodesics\n"
      ],
      "metadata": {
        "id": "T7v2k4JnfgNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 计算测地线并保存 ======\n",
        "curves_single = []\n",
        "energy_logs_single = []\n",
        "curves_ensemble = []\n",
        "energy_logs_ensemble = []\n",
        "\n",
        "for i in range(num_pairs):\n",
        "    pair_file = os.path.join(save_dir, f\"pair_{i}.pt\")\n",
        "\n",
        "    if os.path.exists(pair_file):\n",
        "        # **已存在，直接加载**\n",
        "        data = torch.load(pair_file, weights_only=False)\n",
        "        curves_single.append(data[\"curve_single\"])\n",
        "        energy_logs_single.append(data[\"energy_log_single\"])\n",
        "        curves_ensemble.append(data[\"curve_ensemble\"])\n",
        "        energy_logs_ensemble.append(data[\"energy_log_ensemble\"])\n",
        "        print(f\"点对 {i} 已加载\")\n",
        "    else:\n",
        "        # **计算 single**\n",
        "        c0, c1 = z_pairs_single[i, 0].to(device), z_pairs_single[i, 1].to(device)\n",
        "        curve_single, energy_log_single = optimize_geodesic(\n",
        "            c0, c1, decoders=[vae_single.decoders[0]],\n",
        "            T=T, steps=steps, lr=lr, device=device,\n",
        "            early_stopping_n=100, early_stopping_delta=1e-4\n",
        "        )\n",
        "\n",
        "        # **计算 ensemble**\n",
        "        c0_ens, c1_ens = z_pairs_ensemble[i, 0].to(device), z_pairs_ensemble[i, 1].to(device)\n",
        "        curve_ensemble, energy_log_ensemble = optimize_geodesic(\n",
        "            c0_ens, c1_ens, decoders=vae_ensemble.decoders,\n",
        "            T=T, steps=steps, lr=lr, device=device\n",
        "        )\n",
        "\n",
        "        # **存储结果**\n",
        "        torch.save({\n",
        "            \"curve_single\": curve_single,\n",
        "            \"curve_ensemble\": curve_ensemble,\n",
        "            \"energy_log_single\": energy_log_single,\n",
        "            \"energy_log_ensemble\": energy_log_ensemble\n",
        "        }, pair_file)\n",
        "\n",
        "        print(f\"点对 {i} 计算完成，已保存到 {pair_file}\")\n",
        "\n",
        "        # **加载计算结果，保证后续代码可用**\n",
        "        curves_single.append(curve_single)\n",
        "        energy_logs_single.append(energy_log_single)\n",
        "        curves_ensemble.append(curve_ensemble)\n",
        "        energy_logs_ensemble.append(energy_log_ensemble)\n",
        "\n",
        "    # **画能量曲线**\n",
        "    plot_energy_log_single(energy_logs_single[-1], i, 1)\n",
        "    plot_energy_log_single(energy_logs_ensemble[-1], i, len(vae_ensemble.decoders))\n",
        "\n",
        "    # **画测地线**\n",
        "    plot_geodesics_progress(latent_z_single, labels_single, z_pairs_single[:i+1], curves_single, 1, i)\n",
        "    plot_geodesics_progress(latent_z_ensemble, labels_ensemble, z_pairs_ensemble[:i+1], curves_ensemble, len(vae_ensemble.decoders), i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qD6yp03YkBz",
        "outputId": "3bbd66cf-9830-44af-b3e3-83662c2bcd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 30.850645:   4%|▍         | 173/4200 [03:24<1:18:44,  1.17s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact,different points has different decreasing covergence speed, so I guess we can use early stopping, setting max=5000, if within patience=50 steps , the energy is basically the same, then early stop.\n",
        "\n",
        "just refer to the orginial paper (also use early stopping)\n",
        "https://github.com/mustass/ensertainty/blob/main/configs/inference/ensemble_geodesics.yaml"
      ],
      "metadata": {
        "id": "zHTCa9_w2-Ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.3 plot the required comparision plot of geodesics"
      ],
      "metadata": {
        "id": "ee_1ltsxxKHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Plotting Function ======\n",
        "sample_steps=32 #after optimizing , we get final curve. using how many points to draw this curve\n",
        "# 生成 25 种不同的颜色（从 colormap 获取）\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, 25))  # 可以换成其他 colormap，如 plt.cm.jet\n",
        "\n",
        "def plot_geodesics(latent_z, labels, z_pairs, curves, title, out_path):\n",
        "    \"\"\"\n",
        "    Plot geodesic paths in the latent space.\n",
        "\n",
        "    Parameters:\n",
        "    - latent_z: Latent representations of the test dataset.\n",
        "    - labels: Corresponding class labels.\n",
        "    - z_pairs: Pairs of latent points between which geodesics are computed.\n",
        "    - curves: Optimized geodesic curves.\n",
        "    - title: Plot title.\n",
        "    - out_path: File path to save the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    scatter = plt.scatter(latent_z[:, 0], latent_z[:, 1], c=labels, cmap=\"tab10\", s=8, alpha=0.4)\n",
        "    t_vals = torch.linspace(0, 1, sample_steps).unsqueeze(1).to(device)  # Interpolation points along the geodesic\n",
        "\n",
        "    for i in range(len(curves)):\n",
        "        gamma = curves[i](t_vals).detach().cpu()  # Compute geodesic path\n",
        "        c0, c1 = z_pairs[i, 0], z_pairs[i, 1]\n",
        "\n",
        "        plt.plot(gamma[:, 0], gamma[:, 1], linewidth=1.5, color=colors[i])  # 固定颜色\n",
        "        plt.plot([c0[0], c1[0]], [c0[1], c1[1]], 'k--', linewidth=0.8)  # Dashed line connecting endpoints\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"z1\")\n",
        "    plt.ylabel(\"z2\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(*scatter.legend_elements(), title=\"Class\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9nkLoXc1G_xk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Generate Plots for Single and Ensemble Models ======\n",
        "plot_geodesics(latent_z_single, labels_single, z_pairs_single.cpu(), curves_single,\n",
        "               \"Geodesics in Latent Space (Single Decoder)\", \"vae_single_geodesics.png\")"
      ],
      "metadata": {
        "id": "oJMUMxrcyvq_"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_geodesics(latent_z_ensemble, labels_ensemble, z_pairs_ensemble.cpu(), curves_ensemble,\n",
        "               \"Geodesics in Latent Space (Ensemble Decoder)\", \"vae_ensemble_geodesics.png\")\n"
      ],
      "metadata": {
        "id": "cGADzRRByxnN"
      },
      "execution_count": 81,
      "outputs": []
    }
  ]
}