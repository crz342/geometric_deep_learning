{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6G1rRnYt22w"
   },
   "source": [
    "#0.import and random seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WhlcLeoVsyWt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as td\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OtQ3OkKP1FyY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                           # Python built-in random module\n",
    "    np.random.seed(seed)                        # NumPy random generator\n",
    "    torch.manual_seed(seed)                     # PyTorch CPU random seed\n",
    "    torch.cuda.manual_seed(seed)                # PyTorch current GPU random seed\n",
    "    torch.cuda.manual_seed_all(seed)            # PyTorch all GPUs random seed\n",
    "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior in cuDNN\n",
    "    torch.backends.cudnn.benchmark = False      # Disable auto-optimization to prevent non-deterministic behavior\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)    # Control hash-based randomness in Python\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OuS5xx-nLi5"
   },
   "source": [
    "#1.Dataset  \n",
    "just copy the code provided by the professor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ul7SutXjtmn",
    "outputId": "661da660-1fc5-4c58-d641-a64fe2a9fa16"
   },
   "outputs": [],
   "source": [
    "def subsample(data, targets, num_data, num_classes):\n",
    "    idx = targets < num_classes  # Select samples with class labels less than num_classes (e.g., only classes 0, 1, 2)\n",
    "    new_data = data[idx][:num_data].unsqueeze(1).to(torch.float32) / 255  # Select the first num_data images and normalize to [0,1]\n",
    "    new_targets = targets[idx][:num_data]  # Select corresponding labels for the subsampled images\n",
    "    return torch.utils.data.TensorDataset(new_data, new_targets)  # Create a TensorDataset with the filtered images and labels\n",
    "\n",
    "num_train_data = 2048\n",
    "num_classes = 3\n",
    "\n",
    "train_tensors = datasets.MNIST(\n",
    "    \"data/\", train=True, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
    ")\n",
    "\n",
    "test_tensors = datasets.MNIST(\n",
    "    \"data/\", train=False, download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
    ")\n",
    "train_data = subsample(\n",
    "    train_tensors.data, train_tensors.targets,\n",
    "    num_train_data, num_classes\n",
    ")\n",
    "test_data = subsample(\n",
    "    test_tensors.data, test_tensors.targets,\n",
    "    num_train_data, num_classes\n",
    ")\n",
    "\n",
    "batch_size=32\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "latent_dim=2\n",
    "M=latent_dim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKGEA5qGnR4R"
   },
   "source": [
    "#2.GaussianPrior and Encoder/Decoder\n",
    "Just copy the code provided by the professor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4Ewa8X8LuVcS"
   },
   "outputs": [],
   "source": [
    "class GaussianPrior(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        \"\"\"\n",
    "        Define a Gaussian prior distribution with zero mean and unit variance.\n",
    "\n",
    "                Parameters:\n",
    "        M: [int]\n",
    "           Dimension of the latent space.\n",
    "        \"\"\"\n",
    "        super(GaussianPrior, self).__init__()\n",
    "        self.M = M\n",
    "        self.mean = nn.Parameter(torch.zeros(self.M), requires_grad=False)\n",
    "        self.std = nn.Parameter(torch.ones(self.M), requires_grad=False)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Return the prior distribution.\n",
    "\n",
    "        Returns:\n",
    "        prior: [torch.distributions.Distribution]\n",
    "        \"\"\"\n",
    "        return td.Independent(td.Normal(loc=self.mean, scale=self.std), 1)\n",
    "\n",
    "class GaussianEncoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        \"\"\"\n",
    "        Define a Gaussian encoder distribution based on a given encoder network.\n",
    "\n",
    "        Parameters:\n",
    "        encoder_net: [torch.nn.Module]\n",
    "            The encoder network that takes a tensor of dimension\n",
    "            `(batch_size, feature_dim1, feature_dim2)` as input\n",
    "            and outputs a tensor of dimension `(batch_size, 2M)`,\n",
    "            where M is the dimension of the latent space.\n",
    "        \"\"\"\n",
    "        super(GaussianEncoder, self).__init__()\n",
    "        self.encoder_net = encoder_net\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Given a batch of input data, return a Gaussian distribution over the latent space.\n",
    "\n",
    "        Parameters:\n",
    "        x: [torch.Tensor]\n",
    "            A tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
    "\n",
    "        Returns:\n",
    "        A Gaussian distribution with computed mean and standard deviation.\n",
    "        \"\"\"\n",
    "        mean, std = torch.chunk(self.encoder_net(x), 2, dim=-1)\n",
    "        return td.Independent(td.Normal(loc=mean, scale=torch.exp(std)), 1)\n",
    "\n",
    "        # Example:\n",
    "        # z = torch.randn(4, 10)  # Assume z is a tensor of shape [batch_size=4, 10]\n",
    "        # a, b = torch.chunk(z, 2, dim=-1)\n",
    "        # a and b will have shape [4, 5], as the tensor is split into two parts along the last dimension.\n",
    "def new_encoder():\n",
    "        encoder_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.Softmax(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.Softmax(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 2 * M),\n",
    "        )\n",
    "        return encoder_net\n",
    "class GaussianDecoder(nn.Module):\n",
    "    def __init__(self, decoder_net):\n",
    "        \"\"\"\n",
    "        Define a Gaussian decoder distribution based on a given decoder network.\n",
    "\n",
    "        Parameters:\n",
    "        decoder_net: [torch.nn.Module]\n",
    "            The decoder network that takes a tensor of dimension `(batch_size, M)`\n",
    "            as input, where M is the dimension of the latent space, and outputs a\n",
    "            tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
    "        \"\"\"\n",
    "        super(GaussianDecoder, self).__init__()\n",
    "        self.decoder_net = decoder_net\n",
    "        # self.std = nn.Parameter(torch.ones(28, 28) * 0.5, requires_grad=True)\n",
    "        # In case you want to learn the standard deviation of the Gaussian.\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Given a batch of latent variables, return a Gaussian distribution over the data space.\n",
    "\n",
    "        Parameters:\n",
    "        z: [torch.Tensor]\n",
    "            A tensor of dimension `(batch_size, M)`, where M is the dimension of the latent space.\n",
    "\n",
    "        Returns:\n",
    "        A Gaussian distribution with computed mean and a fixed standard deviation.\n",
    "        \"\"\"\n",
    "        means = self.decoder_net(z)\n",
    "        return td.Independent(td.Normal(loc=means, scale=1e-1), 3) #note the variance of decoder is fixed\n",
    "        # This defines a 784-dimensional independent normal distribution, where each dimension is independent.\n",
    "def new_decoder():\n",
    "        decoder_net = nn.Sequential(\n",
    "            nn.Linear(M, 512),\n",
    "            nn.Unflatten(-1, (32, 4, 4)),\n",
    "            nn.Softmax(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=0),\n",
    "            nn.Softmax(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Softmax(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "        )\n",
    "        return decoder_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3nNIR4xoM5V"
   },
   "source": [
    "#3.VAE\n",
    "having changed the provided code ,so that for each mini-batch of data, we randomly sample a decoder and take a gradient step to optimize the ELBO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qKI-kp2_2Kaj"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, prior, decoders, encoder):\n",
    "        \"\"\"\n",
    "        Variational Autoencoder (VAE) with multiple decoders.\n",
    "\n",
    "        Parameters:\n",
    "        prior: [torch.nn.Module]\n",
    "            The prior distribution over the latent space.\n",
    "        decoders: [list of torch.nn.Module]\n",
    "            A list containing multiple decoders.\n",
    "        encoder: [torch.nn.Module]\n",
    "            The encoder network that maps input data to a latent distribution.\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "        self.prior = prior\n",
    "        self.decoders = nn.ModuleList(decoders)  # Use ModuleList to allow PyTorch to properly track parameters\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def elbo(self, x, decoder_idx):\n",
    "        \"\"\"\n",
    "        Compute the Evidence Lower Bound (ELBO) for a given input and selected decoder.\n",
    "\n",
    "        Parameters:\n",
    "        x: [torch.Tensor]\n",
    "            The input data tensor.\n",
    "        decoder_idx: [int]\n",
    "            The index of the decoder to be used.\n",
    "\n",
    "        Returns:\n",
    "        The computed ELBO value.\n",
    "        \"\"\"\n",
    "        q = self.encoder(x)  # Encode input into a latent distribution\n",
    "        z = q.rsample()  # Sample from the latent distribution using the reparameterization trick\n",
    "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
    "\n",
    "        elbo = torch.mean(\n",
    "            decoder(z).log_prob(x) - q.log_prob(z) + self.prior().log_prob(z)\n",
    "        )  # Compute ELBO using the likelihood, posterior, and prior\n",
    "\n",
    "        return elbo\n",
    "\n",
    "    def sample(self, decoder_idx, n_samples=1):\n",
    "        \"\"\"\n",
    "        Generate samples from the specified decoder.\n",
    "\n",
    "        Parameters:\n",
    "        decoder_idx: [int]\n",
    "            The index of the decoder to be used.\n",
    "        n_samples: [int, default=1]\n",
    "            The number of samples to generate.\n",
    "\n",
    "        Returns:\n",
    "        A batch of generated samples.\n",
    "        \"\"\"\n",
    "        z = self.prior().sample(torch.Size([n_samples]))  # Sample from the prior distribution\n",
    "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
    "        return decoder(z).sample()  # Generate samples from the decoder\n",
    "\n",
    "    def forward(self, x, decoder_idx):\n",
    "        \"\"\"\n",
    "        Compute the negative ELBO for optimization.\n",
    "\n",
    "        Parameters:\n",
    "        x: [torch.Tensor]\n",
    "            The input data tensor.\n",
    "        decoder_idx: [int]\n",
    "            The index of the decoder to be used.\n",
    "\n",
    "        Returns:\n",
    "        The negative ELBO value.\n",
    "        \"\"\"\n",
    "        return -self.elbo(x, decoder_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGBEs4iMoT4L"
   },
   "source": [
    "#4.Training vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ORvNA3H97nNp"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizers, data_loader, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_decoders = len(model.decoders)\n",
    "    #total epoch should depende on the number of decoders\n",
    "    total_epochs = epochs * num_decoders\n",
    "    num_steps = len(data_loader) * total_epochs\n",
    "    epoch = 0\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    def noise(x, std=0.05):\n",
    "        eps = std * torch.randn_like(x)\n",
    "        return torch.clamp(x + eps, min=0.0, max=1.0)\n",
    "\n",
    "    with tqdm(range(num_steps)) as pbar:\n",
    "        for step in pbar:\n",
    "            try:\n",
    "                x = next(iter(data_loader))[0]\n",
    "                x = noise(x.to(device))\n",
    "                model=model\n",
    "                idx = torch.randint(0, num_decoders, (1,)).item()\n",
    "                #for each mini-batch of data, we randomly sample a decoder\n",
    "                #and take a gradient step to optimize the ELBO of  that decoder\n",
    "                # if we [1]\n",
    "                optimizer = optimizers[idx]\n",
    "                optimizer.zero_grad()\n",
    "                loss = model(x, decoder_idx=idx) #correspond to the changed part in VAE\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_val = loss.detach().cpu().item()\n",
    "                losses.append(loss_val)\n",
    "\n",
    "                if step % 5 == 0:\n",
    "                    pbar.set_description(\n",
    "                        f\"epoch={epoch}, step={step}, decoder={idx}, loss={loss_val:.1f}\"\n",
    "                    )\n",
    "                if (step + 1) % len(data_loader) == 0:\n",
    "                    epoch += 1\n",
    "            except KeyboardInterrupt:\n",
    "                print(f\"Stopped at epoch {epoch}, step {step}, loss {loss_val:.1f}\")\n",
    "                break\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DAYjbcQ05-xL"
   },
   "outputs": [],
   "source": [
    "#because in part B we need 10 independent VAEs with  decoders 1,2,3, so I define a new train function\n",
    "#S is the number of the decoders\n",
    "def train_single_vae(seed, save_path, S, epochs_per_decoder):\n",
    "    set_seed(seed)\n",
    "    decoders = [GaussianDecoder(new_decoder()) for _ in range(S)]\n",
    "    #instantiating  S randomly initialized decoders\n",
    "    # note: set_seed(1001) only ensure the next time we run set_seed(1001), it's still the SAME randomly three decoders\n",
    "    # it will not destroy of the randomness of three different decoders\n",
    "    # [dd1,dd2,dd0]  [dd1,dd0,dd2]\n",
    "    encoder = GaussianEncoder(new_encoder())\n",
    "    prior = GaussianPrior(M)\n",
    "\n",
    "    model = VAE(prior, decoders, encoder).to(device)\n",
    "   # I just use the learning rate provided\n",
    "    optimizers = [\n",
    "        torch.optim.Adam(\n",
    "            list(model.encoder.parameters()) + list(decoder.parameters()), lr=1e-3\n",
    "        )\n",
    "        for decoder in model.decoders\n",
    "    ]\n",
    "\n",
    "    losses = train(model, optimizers, mnist_train_loader, epochs_per_decoder)\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    plt.figure()\n",
    "    plt.plot(range(5000, len(losses)), losses[5000:])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"ELBO Loss\")\n",
    "    plt.title(f\"Training Loss (Seed {seed}) [After 5000 Steps]\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path.replace(\".pt\", \"_loss.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUldcuA2MxP"
   },
   "source": [
    "#5 train 10 VAES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C21oFWuCz8Nb"
   },
   "source": [
    "train 10 VAES with different decoder_counts,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_v-LUru9r52"
   },
   "source": [
    "I think this depends on how you implemented the retrainings.\n",
    "\n",
    "If you did something like :\n",
    "## Training:\n",
    "for each training run:\n",
    "    train model with max_number_of_decoders\n",
    "   10 independent vaes and 10 encoders\n",
    "## Geodesics\n",
    "for number_of_decoders in range(1,max_number_of_decoders):\n",
    "    compute_geodesics using number_of_decoders\n",
    "Resulting in 10 training runs, then the blue curve should be constant as the variation of the Euclidean distances should not vary.\n",
    "\n",
    "\n",
    "The difference is in whether you have 10 encoders\n",
    "\n",
    "We advise you to follow the first approach as it is computationally cheaper. But doing the second approach is by no means wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "thxtKogl6GGG"
   },
   "outputs": [],
   "source": [
    "def train_super_vae_models(Q=10, epochs_per_decoder=400, base_seed=1000, max_decoder_num=3):\n",
    "    folder = f\"experiments/vae_d{max_decoder_num}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    for i in range(Q):\n",
    "        seed = base_seed + i\n",
    "        name = f\"vae_d{max_decoder_num}_seed{seed}\"\n",
    "        save_path = os.path.join(folder, f\"{name}.pt\")\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"Skipping training for {name}, checkpoint exists.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Training VAE: decoder={max_decoder_num}, seed={seed}\")\n",
    "        train_single_vae(seed, save_path, S=max_decoder_num, epochs_per_decoder=epochs_per_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LHu457k0GDI",
    "outputId": "e90e2255-59af-43a1-e462-6dacc29b558b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping training for vae_d3_seed1000, checkpoint exists.\n",
      "Skipping training for vae_d3_seed1001, checkpoint exists.\n",
      "Training VAE: decoder=3, seed=1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/192 [00:00<?, ?it/s]/Users/liangyu/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "epoch=2, step=190, decoder=1, loss=1441.6: 100%|██████████| 192/192 [00:02<00:00, 79.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=155, decoder=2, loss=3340.2:  81%|████████▏ | 156/192 [00:01<00:00, 83.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped at epoch 2, step 156, loss 3340.2\n",
      "Training VAE: decoder=3, seed=1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=1, loss=1727.1: 100%|██████████| 192/192 [00:02<00:00, 85.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=1, loss=1375.7: 100%|██████████| 192/192 [00:02<00:00, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=2, loss=1592.6: 100%|██████████| 192/192 [00:02<00:00, 82.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=0, loss=1787.2: 100%|██████████| 192/192 [00:02<00:00, 84.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=1, loss=1435.0: 100%|██████████| 192/192 [00:02<00:00, 85.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE: decoder=3, seed=1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, step=190, decoder=0, loss=1450.8: 100%|██████████| 192/192 [00:02<00:00, 87.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#Q is the number of VAES,here Q=2 epoch=2 just for testing the code.\n",
    "train_super_vae_models(Q=10, epochs_per_decoder=400, base_seed=1000,max_decoder_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ps_jve53nDOX",
    "outputId": "78c6f504-0cd3-4236-c80a-7e590c8d6df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vae_d3_seed1000\n"
     ]
    }
   ],
   "source": [
    "def load_all_vaes(base_folder=\"experiments\", max_decoder_num=3, Q=1, base_seed=1000, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    all_models = {}\n",
    "\n",
    "    folder = os.path.join(base_folder, f\"vae_d{max_decoder_num}\")\n",
    "\n",
    "    for i in range(Q):\n",
    "        seed = base_seed + i\n",
    "        name = f\"vae_d{max_decoder_num}_seed{seed}\"\n",
    "        path = os.path.join(folder, f\"{name}.pt\")\n",
    "\n",
    "        # construct model structure\n",
    "        decoders = [GaussianDecoder(new_decoder()) for _ in range(max_decoder_num)]\n",
    "        encoder = GaussianEncoder(new_encoder())\n",
    "        prior = GaussianPrior(M=2)  # latent_dim = 2\n",
    "\n",
    "        model = VAE(prior, decoders, encoder).to(device)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        all_models[name] = model\n",
    "        print(f\"Loaded {name}\")\n",
    "\n",
    "    return all_models\n",
    "models = load_all_vaes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oRHzb200mKG",
    "outputId": "b96127cc-d048-4e26-9e70-66e39f3c0270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vae_d3_seed1000\n",
      "Loaded vae_d3_seed1001\n",
      "GaussianEncoder(\n",
      "  (encoder_net): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Softmax(dim=None)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Softmax(dim=None)\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "GaussianDecoder(\n",
      "  (decoder_net): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): Unflatten(dim=-1, unflattened_size=(32, 4, 4))\n",
      "    (2): Softmax(dim=None)\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Softmax(dim=None)\n",
      "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (8): Softmax(dim=None)\n",
      "    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#At convergence, we\n",
    "#have access to one encoder and Sdecoders.\n",
    "\n",
    "#for test\n",
    "\n",
    "# one model\n",
    "m = models[\"vae_d3_seed1001\"]\n",
    "encoder = m.encoder\n",
    "decoder0 = m.decoders[0]\n",
    "print(encoder)\n",
    "print(decoder0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRPm7LAoJHKR"
   },
   "source": [
    "## 5.2 check vae quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lFuV-aJ6JF-h"
   },
   "outputs": [],
   "source": [
    "#5.2\n",
    "def visualize_all_vaes_all_decoders(models, test_loader, output_folder=\"vae_vis_outputs\", device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.eval()\n",
    "        out_dir = os.path.join(output_folder, name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        num_decoders = len(model.decoders)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            data = next(iter(test_loader))[0].to(device)\n",
    "            z = model.encoder(data).mean\n",
    "\n",
    "            for decoder_idx in range(num_decoders):\n",
    "                # 1. Sampling\n",
    "                samples = model.sample(decoder_idx=decoder_idx, n_samples=64).cpu()\n",
    "                sample_path = os.path.join(out_dir, f\"samples_decoder{decoder_idx}.png\")\n",
    "                save_image(samples.view(64, 1, 28, 28), sample_path)\n",
    "\n",
    "                # 2. Reconstruction\n",
    "                recon = model.decoders[decoder_idx](z).mean\n",
    "                recon_path = os.path.join(out_dir, f\"reconstruction_decoder{decoder_idx}.png\")\n",
    "                save_image(torch.cat([data.cpu(), recon.cpu()], dim=0), recon_path)\n",
    "\n",
    "            print(f\"✅ Saved all decoders for {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOTzgtzaJY6o",
    "outputId": "1cd15fc8-22f1-45b1-96eb-a33d29f315dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved all decoders for vae_d3_seed1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangyu/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualize_all_vaes_all_decoders(models, mnist_test_loader, output_folder=\"vae_vis_outputs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7_VxVHhFZzr"
   },
   "source": [
    "#6 cruve and energy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_8WxRNksmWk"
   },
   "source": [
    "##6.1 cubiccurve 参数T=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "V7r1Tut2FzsN"
   },
   "outputs": [],
   "source": [
    "# page 68 cubiccurve(t) core code\n",
    "class CubicCurve(nn.Module):\n",
    "    def __init__(self, c0, c1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        c0: torch.Tensor, start point (D,)\n",
    "        c1: torch.Tensor, end point (D,)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available\n",
    "        self.T = 256  # Number of segments, typically in [64, 256] in Q2 we use 64\n",
    "        self.D = c0.shape[0]  # Dimensionality of the curve\n",
    "\n",
    "        self.register_buffer(\"c0\", c0.to(self.device))  # Register start point as buffer (non-trainable)\n",
    "        self.register_buffer(\"c1\", c1.to(self.device))  # Register end point as buffer (non-trainable)\n",
    "\n",
    "        # Initialize intermediate control points along a straight line from c0 to c1\n",
    "        # This ensures the initial curve is linear before optimization\n",
    "        intermediate_points = torch.stack([\n",
    "            c0 + (c1 - c0) * (i + 1) / self.T  # Equally spaced points between c0 and c1\n",
    "            for i in range(self.T - 1)\n",
    "        ], dim=0).to(self.device)  # Shape: (T-1, D), stacked along the 0-th dimension\n",
    "\n",
    "        self.c_t = nn.Parameter(intermediate_points)  # Make intermediate points trainable\n",
    "\n",
    "        # Create a uniform grid of time values from 0 to 1 with (T + 1) points\n",
    "        self.register_buffer(\"t_grid\", torch.linspace(0, 1, self.T + 1, device=self.device))\n",
    "        # t0, t1, ..., tT\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Compute the value of the piecewise linear curve at position t\n",
    "\n",
    "        Parameters:\n",
    "        t: torch.Tensor, shape (...,), range [0,1]\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor, shape (..., D)\n",
    "\n",
    "        Each segment is linearly interpolated between two control points:\n",
    "        Given control points p0 and p1, and a scalar alpha ∈ [0, 1],\n",
    "        interpolation formula is: p(t) = (1 - alpha) * p0 + alpha * p1\n",
    "        where alpha = (t - t0) / (t1 - t0)\n",
    "        \"\"\"\n",
    "        t = t.to(self.device)  # Move t to the appropriate device\n",
    "\n",
    "        # Concatenate all control points: [c0, ..., c_t, ..., c1], shape (T+1, D)\n",
    "        control_points = torch.cat([self.c0.unsqueeze(0), self.c_t, self.c1.unsqueeze(0)], dim=0)\n",
    "        # unsqueeze(0) adds a new dimension at index 0: (D,) → (1, D)\n",
    "\n",
    "        # For each t, find the corresponding segment index in t_grid\n",
    "        # Example: t_grid = [0.0, 0.25, 0.5, 0.75, 1.0], t = 0.6 → returns 3\n",
    "        # Even t = 0.5 returns 3 (right=True), then idx = 3 - 1 = 2\n",
    "\n",
    "        idx = torch.searchsorted(self.t_grid, t, right=True) - 1  # Get the left segment index\n",
    "        idx = idx.clamp(0, self.T - 1)  # Clamp idx to range [0, T - 1] to avoid overflow\n",
    "        # If idx == T, then idx + 1 is out of bounds, so clamp to T - 1\n",
    "\n",
    "        # Get start and end times of the segment\n",
    "        t0, t1 = self.t_grid[idx], self.t_grid[idx + 1]\n",
    "        # For example, t = 0.6 → segment is [t2, t3] = [0.5, 0.75]\n",
    "\n",
    "        # Compute normalized position within the segment\n",
    "        alpha = (t - t0) / (t1 - t0)\n",
    "\n",
    "        # Get the corresponding control points for interpolation\n",
    "        ct0, ct1 = control_points[idx], control_points[idx + 1]\n",
    "\n",
    "        # Perform linear interpolation:\n",
    "        # p(t) = (1 - alpha) * c0 + alpha * c1\n",
    "        # Equivalent to:\n",
    "        # If t ∈ [t_i, t_{i+1}]:\n",
    "        #     p(t) = c_i + (c_{i+1} - c_i) * (t - t_i) / (t_{i+1} - t_i)\n",
    "        #          = (1 - alpha) * c_i + alpha * c_{i+1}\n",
    "        return (1 - alpha.unsqueeze(-1)) * ct0 + alpha.unsqueeze(-1) * ct1  # (..., D), broadcast over last dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuBRA6srsq2u"
   },
   "source": [
    "##6.2 compute_energy\n",
    "\n",
    "$$\n",
    "\\mathcal{E}[\\gamma] \\approx \\sum_{t=0}^{T-1} \\mathbb{E}_{\\theta, \\theta' \\sim q(\\theta) q(\\theta)}\n",
    "\\left[ \\left\\| f_{\\theta} (\\gamma(t + \\frac{1}{T})) - f_{\\theta'} (\\gamma(t / T)) \\right\\|^2 \\right]\n",
    "$$\n",
    "\n",
    "$f_{\\theta}$ $f_{\\theta'}$ denotes deoder ensemble members drawn uniformly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "L1ntkmnPoo0g"
   },
   "outputs": [],
   "source": [
    "def compute_curve_energy(curve, decoders, T, fixed_indices=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute the energy of a curve using fixed decoder indices (no Monte Carlo).\n",
    "\n",
    "    Parameters:\n",
    "    - curve: An instance of CubicCurve\n",
    "    - decoders: List of decoder modules\n",
    "    - T: Number of time steps\n",
    "    - fixed_indices: Pre-fixed decoder indices [(idx1_t0, idx2_t0), (idx1_t1, idx2_t1), ...]\n",
    "    - device: Computing device\n",
    "\n",
    "    Returns:\n",
    "    - Scalar energy value\n",
    "    \"\"\"\n",
    "    total_energy = 0.0  # Accumulate energy over all time steps\n",
    "\n",
    "    for i in range(T):\n",
    "        t0 = torch.tensor([i / T], device=device, dtype=torch.float32)\n",
    "        t1 = torch.tensor([(i + 1) / T], device=device, dtype=torch.float32)\n",
    "\n",
    "        x0 = curve(t0)  # γ(t0), shape [1, D]\n",
    "        x1 = curve(t1)  # γ(t1), shape [1, D]\n",
    "\n",
    "        # Get fixed decoder indices for this segment\n",
    "        idx1, idx2 = fixed_indices[i]\n",
    "        #why i don't write this\n",
    "        # idx1,idx2=random(./)\n",
    "        # Compute decoder outputs at t0 and t1\n",
    "        y0 = decoders[idx1](x0).mean\n",
    "        y1 = decoders[idx2](x1).mean\n",
    "        #You must implement an algorithm to compute geodesics under the pull-back metric\n",
    "#associated with the mean of the Gaussian decoder.\n",
    "        # Energy = L2 norm between decoded outputs\n",
    "        energy = torch.norm(y1 - y0, p=2) **2\n",
    "\n",
    "        total_energy += energy\n",
    "\n",
    "    return total_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e6UxF2PO3Br"
   },
   "source": [
    "##6.3 optimize_geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "JqEQ2nKLotZb"
   },
   "outputs": [],
   "source": [
    "def optimize_geodesic(c0, c1, decoders, T, steps, lr, device,\n",
    "                      early_stopping_n, early_stopping_delta):\n",
    "    \"\"\"\n",
    "    Optimize a geodesic curve while ensuring the objective function remains unchanged during optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - c0: Starting point\n",
    "    - c1: Endpoint\n",
    "    - decoders: List of decoder modules\n",
    "    - T: Number of time steps\n",
    "    - steps: Number of optimization iterations\n",
    "    - lr: Learning rate\n",
    "    - device: Computing device\n",
    "    - early_stopping_n: Number of steps to check for early stopping\n",
    "    - early_stopping_delta: Minimum required improvement to continue\n",
    "\n",
    "    Returns:\n",
    "    - Optimized curve\n",
    "    - Logged energy values\n",
    "    \"\"\"\n",
    "    curve = CubicCurve(c0, c1).to(device)\n",
    "    optimizer = torch.optim.Adam(curve.parameters(), lr=lr)\n",
    "\n",
    "    # 内部直接定义调度器（自动学习率衰减）\n",
    "    # min represent we are minimizing the data\n",
    "    #factor - after the I also added a `torch.optim.lr_scheduler.ReduceLROnPlateau`,\n",
    "    #which reduces the learning rate by a factor of 0.5 if the change is less than 1e-3 within 100 steps,\n",
    "    # if the change is less than 1e-3 within 300 steps, early stopping is triggered. Of course,\n",
    "    # this is just based on experience.I set 2000steps and it’s very slow.\n",
    "    #I  don’t think my method is good.\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.7,\n",
    "        patience=50,\n",
    "        threshold=1e-3,\n",
    "        verbose=True,\n",
    "        min_lr=1e-4\n",
    "    )\n",
    "\n",
    "    energy_log = []\n",
    "\n",
    "    #generate inside the function but not inside the optimization loop\n",
    "    fixed_indices = [(torch.randint(0, len(decoders), (1,), device=device).item(),\n",
    "                      torch.randint(0, len(decoders), (1,), device=device).item())\n",
    "                     for _ in range(T)]\n",
    "\n",
    "    best_energy = float('inf')\n",
    "    no_improve_count = 0\n",
    "\n",
    "    with tqdm(range(steps)) as pbar:\n",
    "        for step in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            energy = compute_curve_energy(curve, decoders, T=T, fixed_indices=fixed_indices, device=device)\n",
    "            energy.backward()\n",
    "            optimizer.step()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            # 衰减学习率（每步传当前 energy 给 scheduler）\n",
    "            energy_value = energy.item()\n",
    "            scheduler.step(energy_value)\n",
    "            energy_log.append(energy_value)\n",
    "\n",
    "            # Early Stopping（从 step >= 300 起判断）\n",
    "            if step >= 500:\n",
    "                if energy_value < best_energy - early_stopping_delta:\n",
    "                    best_energy = energy_value\n",
    "                    no_improve_count = 0\n",
    "                else:\n",
    "                    no_improve_count += 1\n",
    "\n",
    "                if no_improve_count >= early_stopping_n:\n",
    "                    print(f\"Early stopping at step {step}, energy: {energy_value:.6f}, LR: {current_lr:.2e}\")\n",
    "                    break\n",
    "\n",
    "            pbar.set_description(f\"Energy: {energy_value:.6f}, LR: {current_lr:.2e}\")\n",
    "\n",
    "    return curve, energy_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE52pKwas5TJ"
   },
   "source": [
    "# 7 10random latent_varibale pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKh_3_IruXFC"
   },
   "source": [
    "##7.1 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "u66xdqOMJYLB"
   },
   "outputs": [],
   "source": [
    "# ====== Extract all images from the test set ======\n",
    "all_test_x = []\n",
    "all_test_y = []\n",
    "for x, y in mnist_test_loader:\n",
    "    all_test_x.append(x)\n",
    "    all_test_y.append(y)\n",
    "\n",
    "all_test_x = torch.cat(all_test_x, dim=0)  # shape: [N, 1, 28, 28]\n",
    "all_test_y = torch.cat(all_test_y, dim=0)  # shape: [N]\n",
    "\n",
    "# ====== random seed3 :to ensure everyone  get the same test points 1 global 2 vae  ======\n",
    "random.seed(42) #very important!\n",
    "\n",
    "# ====== Sample 10 image pairs ==here is a way to split the work, one 2-3 pairs====\n",
    "num_pairs = 25 #要求用10个测试点对\n",
    "N = all_test_x.shape[0] #total number of test points\n",
    "indices = random.sample(range(N), 2 * num_pairs) #from this take 20 pair images\n",
    "\n",
    "# ====== Construct image pair list: [(x_i, x_j), ...] ======\n",
    "test_image_pairs = [\n",
    "    (all_test_x[indices[i]], all_test_x[indices[i + 1]])\n",
    "    for i in range(0, 2 * num_pairs, 2)\n",
    "]  # Each element shape: ([1, 28, 28], [1, 28, 28]) [0,1][2,3][4,5])\n",
    "# let (yi,yj ) denote a fixed pair of test points (these should be the same across different models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSY9QZwW2FJh"
   },
   "source": [
    "##7.2 geodesic_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySLBgMGFg2IT"
   },
   "source": [
    "x1 = x1.unsqueeze(0)  # Convert x1 to shape [1, C, H, W] as a batch input\n",
    "# Models usually expect batched input, even for a single image\n",
    "\n",
    "posterior = model.encoder(x1)  # Pass the image through the VAE encoder, returns a distribution object\n",
    "\n",
    "z = posterior.base_dist.loc  # Get the mean vector from the underlying distribution (usually Normal(mean, std))\n",
    "\n",
    "z = z.squeeze(0)  # Remove the batch dimension: [1, latent_dim] → [latent_dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EqZKr61Y1A-"
   },
   "source": [
    "下面的代码两个随机种子助教在群里明确回复了。第一个不能和pair_idx和有。第二个要和pair_idx有关（因为是在用3个decoder算那个vae下,不同测试点的能量的蒙特卡罗近似，用随机算的更准确）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZRgteRMkqF7"
   },
   "source": [
    "```python\n",
    "# This logic is quite tricky and must be understood carefully. GPT might directly give a wrong answer.\n",
    "# Suppose the number of decoders is 2.\n",
    "# For a given data pair, we need to evaluate it using different VAEs. The way we compute is to treat it as a 2-decoder VAE\n",
    "# (even though it may have been trained with 3 decoders originally, we treat it as having only 2 decoders).\n",
    "# We can, for instance, take the same index set (e.g., 1,2) for all VAEs. Since each VAE is different, fixing indices 1,2 or sampling them randomly makes no difference.\n",
    "# The decoder indices 1,2 from VAE1 and 2,3 from VAE2 are equally random—just random selections.\n",
    "# Therefore, the hash function and the M-VAE index can be either related or unrelated—it doesn’t matter. To be extra safe, they can be related.\n",
    "# But can they be related to pair_idx?\n",
    "# That is, can we, for example, assign the same VAE to all data pairs, and for the first pair use decoder indices 1,2, for the second pair 2,3, etc.?\n",
    "# I believe this is not allowed. Because if we do this over 10 data pairs, it’s as if the VAE has 3 decoders again!\n",
    "# What we actually want to evaluate is a VAE with only 2 decoders (fixed for the whole dataset).\n",
    "# So, it absolutely must not depend on pair_idx.\n",
    "# Regarding the outer loop: whether the number of decoders is 1 or 2, using the same random seed or not has no effect.\n",
    "# Because decoder1 selects 1 index, and decoder2 selects 2 indices—different amounts of data.\n",
    "# Moreover, even if there’s some relationship—e.g., decoder1 selects index 1, decoder2 selects indices 1,2, or decoder1 selects 2, and decoder2 selects 2,3—\n",
    "# This doesn’t work either. If it happens to be the same VAE, then having two decoders is always more powerful than one.\n",
    "# Since we are comparing the performance difference between 1 and 2 decoders, these selections must be independent.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbdnj85ctN5K"
   },
   "source": [
    "Next, about random seed sampling. First of all, can it be placed inside the optimization loop? Absolutely not!  \n",
    "If so, for the same VAE and different data points, the sampling during each optimization would be the same in the for i_T loop—making the objective function exactly the same.  \n",
    "This weakens the effect of having 10 different data points. Moreover, the calculation is originally based on an expectation—those 10 points effectively perform 10 rounds of Monte Carlo sampling.  \n",
    "So the hash function must depend on the data point. Each data point’s sampling must be independent.\n",
    "\n",
    "Next, regarding the VAE: since the VAEs are independent, whether to fix the decoder choice per optimization or not doesn’t matter. To be conservative, we do fix it.\n",
    "\n",
    "Finally, regarding the decoder count: same logic as before—it’s best to make them independent.  \n",
    "If decoder count 1 and 2 are correlated, then decoder1 and decoder2 might differ not just in the number of decoders, but because decoder2 includes more powerful decoders.  \n",
    "We want to isolate the effect of decoder count alone, so they must be sampled independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "OeH2LbBXuVXY"
   },
   "outputs": [],
   "source": [
    "def compute_all_geodesic_distances(models_dict, test_image_pairs, max_decoder_num, device, T, steps, lr, num_vaes, early_stopping_n, early_stopping_delta):\n",
    "    distances = []  # shape: [decoder_num][pair_idx][vae_idx]\n",
    "    curves = []     # shape: 同上，保存每条曲线（tensor）\n",
    "\n",
    "    for number_of_decoders in range(1, max_decoder_num + 1):\n",
    "        pair_results_energy = []  # 当前 decoder_num 下所有 pair 的能量结果\n",
    "        pair_results_curve = []   # 当前 decoder_num 下所有 pair 的曲线结果\n",
    "\n",
    "        for pair_idx, (x1, x2) in enumerate(test_image_pairs):\n",
    "            vae_energies = []  # 当前 pair，所有 vae 的能量\n",
    "            vae_curves = []    # 当前 pair，所有 vae 的曲线\n",
    "\n",
    "            for m in range(num_vaes):\n",
    "                model_name = f\"vae_d{max_decoder_num}_seed{1000 + m}\"\n",
    "                model = models_dict[model_name]\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    z1 = model.encoder(x1.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "                    z2 = model.encoder(x2.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "\n",
    "                result_dir = f\"results_geodesic/decoders_{number_of_decoders}/pair_{pair_idx}/vae_{m}\"\n",
    "                os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "                curve_path = os.path.join(result_dir, \"curve.pt\")\n",
    "                energy_log_path = os.path.join(result_dir, \"energy_log.pt\")\n",
    "\n",
    "                if os.path.exists(curve_path) and os.path.exists(energy_log_path):\n",
    "                    curve = torch.load(curve_path, map_location=device, weights_only=False)\n",
    "                    energy_log = torch.load(energy_log_path, map_location=device, weights_only=False)\n",
    "                    print(f\"✅ Loaded: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
    "                else:\n",
    "                    seed_dec = hash((\"decoder_select\", m, number_of_decoders)) % (2**32)\n",
    "                    random.seed(seed_dec)\n",
    "                    selected_decoders = random.sample(list(model.decoders), number_of_decoders)\n",
    "\n",
    "                    seed_fixed = hash((\"fixed_indices\", m, pair_idx, number_of_decoders)) % (2**32)\n",
    "                    torch.manual_seed(seed_fixed)\n",
    "\n",
    "                    curve, energy_log = optimize_geodesic(\n",
    "                        z1, z2, decoders=selected_decoders, T=T, steps=steps, lr=lr, device=device,\n",
    "                        early_stopping_n=early_stopping_n, early_stopping_delta=early_stopping_delta\n",
    "                    )\n",
    "\n",
    "                    torch.save(curve, curve_path)\n",
    "                    torch.save(energy_log, energy_log_path)\n",
    "                    print(f\"✅ Computed & saved: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
    "\n",
    "                energy = energy_log[-1]\n",
    "                vae_energies.append(energy)\n",
    "                vae_curves.append(curve)\n",
    "\n",
    "            pair_results_energy.append(vae_energies)\n",
    "            pair_results_curve.append(vae_curves)\n",
    "\n",
    "        distances.append(pair_results_energy)\n",
    "        curves.append(pair_results_curve)\n",
    "\n",
    "    return distances, curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk_T7IBp2AU8",
    "outputId": "fa2c22a3-9cf5-4d9a-9679-a4d3e0cc0a61",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: decoders=1, pair=0, vae=0\n",
      "✅ Loaded: decoders=1, pair=1, vae=0\n",
      "✅ Loaded: decoders=1, pair=2, vae=0\n",
      "✅ Loaded: decoders=1, pair=3, vae=0\n",
      "✅ Loaded: decoders=1, pair=4, vae=0\n",
      "✅ Loaded: decoders=1, pair=5, vae=0\n",
      "✅ Loaded: decoders=1, pair=6, vae=0\n",
      "✅ Loaded: decoders=1, pair=7, vae=0\n",
      "✅ Loaded: decoders=1, pair=8, vae=0\n",
      "✅ Loaded: decoders=1, pair=9, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 2.347769, LR: 1.66e-04:  77%|███████▋  | 1535/2000 [18:33<05:37,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1535, energy: 2.347769, LR: 1.66e-04\n",
      "✅ Computed & saved: decoders=1, pair=10, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 5.373148, LR: 1.66e-04:  78%|███████▊  | 1565/2000 [18:33<05:09,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1565, energy: 5.373149, LR: 1.66e-04\n",
      "✅ Computed & saved: decoders=1, pair=11, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 3.628220, LR: 1.16e-04:  84%|████████▍ | 1689/2000 [20:33<03:47,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1689, energy: 3.628218, LR: 1.16e-04\n",
      "✅ Computed & saved: decoders=1, pair=12, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.973430, LR: 1.41e-03: 100%|██████████| 2000/2000 [23:03<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Computed & saved: decoders=1, pair=13, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.045527, LR: 1.66e-04:  42%|████▏     | 839/2000 [06:49<09:27,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 839, energy: 0.045526, LR: 1.66e-04\n",
      "✅ Computed & saved: decoders=1, pair=14, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 1.981453, LR: 1.41e-03: 100%|██████████| 2000/2000 [17:21<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Computed & saved: decoders=1, pair=15, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 1.111566, LR: 4.84e-04:  64%|██████▍   | 1276/2000 [10:49<06:08,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1276, energy: 1.111565, LR: 3.39e-04\n",
      "✅ Computed & saved: decoders=1, pair=16, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 4.130901, LR: 1.16e-04:  82%|████████▏ | 1630/2000 [13:52<03:09,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1630, energy: 4.130900, LR: 1.16e-04\n",
      "✅ Computed & saved: decoders=1, pair=17, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.490134, LR: 1.16e-04:  44%|████▍     | 880/2000 [07:15<09:14,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 880, energy: 0.490133, LR: 1.16e-04\n",
      "✅ Computed & saved: decoders=1, pair=18, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 1.938667, LR: 1.41e-03:  38%|███▊      | 754/2000 [06:15<10:20,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 754, energy: 1.938665, LR: 1.41e-03\n",
      "✅ Computed & saved: decoders=1, pair=19, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 10.438465, LR: 1.00e-04: 100%|██████████| 2000/2000 [16:47<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Computed & saved: decoders=1, pair=20, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.227190, LR: 1.00e-04:  50%|████▉     | 994/2000 [08:29<08:35,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 994, energy: 0.227189, LR: 1.00e-04\n",
      "✅ Computed & saved: decoders=1, pair=21, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 6.337172, LR: 1.16e-04:  71%|███████▏  | 1427/2000 [12:27<05:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1427, energy: 6.337169, LR: 1.16e-04\n",
      "✅ Computed & saved: decoders=1, pair=22, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.391794, LR: 3.39e-04:  56%|█████▌    | 1118/2000 [09:35<07:34,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 1118, energy: 0.391794, LR: 3.39e-04\n",
      "✅ Computed & saved: decoders=1, pair=23, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy: 0.102680, LR: 1.66e-04:  43%|████▎     | 863/2000 [07:20<09:40,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 863, energy: 0.102679, LR: 1.66e-04\n",
      "✅ Computed & saved: decoders=1, pair=24, vae=0\n",
      "✅ Loaded: decoders=2, pair=0, vae=0\n",
      "✅ Loaded: decoders=2, pair=1, vae=0\n",
      "✅ Loaded: decoders=2, pair=2, vae=0\n",
      "✅ Loaded: decoders=2, pair=3, vae=0\n",
      "✅ Loaded: decoders=2, pair=4, vae=0\n",
      "✅ Loaded: decoders=2, pair=5, vae=0\n",
      "✅ Loaded: decoders=2, pair=6, vae=0\n",
      "✅ Loaded: decoders=2, pair=7, vae=0\n",
      "✅ Loaded: decoders=2, pair=8, vae=0\n",
      "✅ Loaded: decoders=2, pair=9, vae=0\n",
      "✅ Loaded: decoders=2, pair=10, vae=0\n",
      "✅ Loaded: decoders=2, pair=11, vae=0\n",
      "✅ Loaded: decoders=2, pair=12, vae=0\n",
      "✅ Loaded: decoders=2, pair=13, vae=0\n",
      "✅ Loaded: decoders=2, pair=14, vae=0\n",
      "✅ Loaded: decoders=2, pair=15, vae=0\n",
      "✅ Loaded: decoders=2, pair=16, vae=0\n",
      "✅ Loaded: decoders=2, pair=17, vae=0\n",
      "✅ Loaded: decoders=2, pair=18, vae=0\n",
      "✅ Loaded: decoders=2, pair=19, vae=0\n",
      "✅ Loaded: decoders=2, pair=20, vae=0\n",
      "✅ Loaded: decoders=2, pair=21, vae=0\n",
      "✅ Loaded: decoders=2, pair=22, vae=0\n",
      "✅ Loaded: decoders=2, pair=23, vae=0\n",
      "✅ Loaded: decoders=2, pair=24, vae=0\n",
      "✅ Loaded: decoders=3, pair=0, vae=0\n",
      "✅ Loaded: decoders=3, pair=1, vae=0\n",
      "✅ Loaded: decoders=3, pair=2, vae=0\n",
      "✅ Loaded: decoders=3, pair=3, vae=0\n",
      "✅ Loaded: decoders=3, pair=4, vae=0\n",
      "✅ Loaded: decoders=3, pair=5, vae=0\n",
      "✅ Loaded: decoders=3, pair=6, vae=0\n",
      "✅ Loaded: decoders=3, pair=7, vae=0\n",
      "✅ Loaded: decoders=3, pair=8, vae=0\n",
      "✅ Loaded: decoders=3, pair=9, vae=0\n",
      "✅ Loaded: decoders=3, pair=10, vae=0\n",
      "✅ Loaded: decoders=3, pair=11, vae=0\n",
      "✅ Loaded: decoders=3, pair=12, vae=0\n",
      "✅ Loaded: decoders=3, pair=13, vae=0\n",
      "✅ Loaded: decoders=3, pair=14, vae=0\n",
      "✅ Loaded: decoders=3, pair=15, vae=0\n",
      "✅ Loaded: decoders=3, pair=16, vae=0\n",
      "✅ Loaded: decoders=3, pair=17, vae=0\n",
      "✅ Loaded: decoders=3, pair=18, vae=0\n",
      "✅ Loaded: decoders=3, pair=19, vae=0\n",
      "✅ Loaded: decoders=3, pair=20, vae=0\n",
      "✅ Loaded: decoders=3, pair=21, vae=0\n",
      "✅ Loaded: decoders=3, pair=22, vae=0\n",
      "✅ Loaded: decoders=3, pair=23, vae=0\n",
      "✅ Loaded: decoders=3, pair=24, vae=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "T = 256 # this T is not the same  as the total segmentation\n",
    "steps = 2000 #optimization step ,\n",
    "lr = 5*1e-2 #learning rate\n",
    "num_vaes = 10 #required 10\n",
    "max_decoder_num = 3\n",
    "early_stopping_n=100\n",
    "early_stopping_delta=1e-4\n",
    "\n",
    "geodesic_distances, geodesic_curves = compute_all_geodesic_distances(\n",
    "    models_dict=models,\n",
    "    test_image_pairs=test_image_pairs,\n",
    "    max_decoder_num=max_decoder_num,\n",
    "    device=device,\n",
    "    T=T,\n",
    "    steps=steps,\n",
    "    lr=lr,\n",
    "    num_vaes=num_vaes,\n",
    "    early_stopping_n=early_stopping_n,\n",
    "    early_stopping_delta=early_stopping_delta\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#加了这一大串，名字还是之前的名字，有报错的话随时和我说\n",
    "def sqrt_nested_distances(distances):\n",
    "    return [\n",
    "        [  # decoder_idx 层\n",
    "            [np.sqrt(d) for d in vae_dists]  # 对每个 vae 的能量开根号\n",
    "            for vae_dists in pair_list       # 遍历所有 pair\n",
    "        ]\n",
    "        for pair_list in distances           # 遍历 decoder_num\n",
    "    ]\n",
    "geodesic_distances = sqrt_nested_distances(geodesic_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoded latent space for: vae_d3_seed1000\n"
     ]
    }
   ],
   "source": [
    "#接下来是画图任务！用这两个vae画partA需要的十个点的图\n",
    "#首先是把，把测试集的全部数据都编码到潜在空间\n",
    "def encode_all_models_latents(models_dict, test_loader, device):\n",
    "    \"\"\"\n",
    "    对所有模型将测试数据编码为潜变量空间坐标。\n",
    "\n",
    "    参数:\n",
    "    - models_dict: 字典，key 为模型名，value 为模型实例\n",
    "    - test_loader: DataLoader，测试数据集\n",
    "    - device: 设备 (cuda 或 cpu)\n",
    "\n",
    "    返回:\n",
    "    - latents_dict: {模型名: (zs, ys)}，zs 是所有测试样本的潜变量表示，ys 是对应标签\n",
    "    \"\"\"\n",
    "    latents_dict = {}\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.eval()\n",
    "        zs, ys = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device)\n",
    "                q = model.encoder(x)\n",
    "                z = q.base_dist.loc\n",
    "                zs.append(z.cpu())\n",
    "                ys.append(y)\n",
    "\n",
    "        zs_all = torch.cat(zs, dim=0)\n",
    "        ys_all = torch.cat(ys, dim=0)\n",
    "        latents_dict[model_name] = (zs_all, ys_all)\n",
    "        print(f\"✅ Encoded latent space for: {model_name}\")\n",
    "\n",
    "    return latents_dict\n",
    "\n",
    "# 调用\n",
    "latents_all_models = encode_all_models_latents(models, mnist_test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoded z_pairs for vae_d3_seed1000\n"
     ]
    }
   ],
   "source": [
    "def encode_test_image_pairs(models_dict, test_image_pairs, device):\n",
    "    \"\"\"\n",
    "    将 test_image_pairs 编码为潜变量空间中的 (z1, z2) 对。\n",
    "\n",
    "    参数：\n",
    "    - models_dict: 所有 VAE 模型的字典\n",
    "    - test_image_pairs: 图像对列表，形如 [(x1, x2), ...]，每个 x 形状是 [1, 28, 28]\n",
    "    - device: cuda 或 cpu\n",
    "\n",
    "    返回：\n",
    "    - z_pairs_dict: {模型名: Tensor[num_pairs, 2, latent_dim]}\n",
    "    \"\"\"\n",
    "    z_pairs_dict = {}\n",
    "\n",
    "    for model_name, model in models_dict.items():\n",
    "        model.eval()\n",
    "        z_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x1, x2 in test_image_pairs:\n",
    "                z1 = model.encoder(x1.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "                z2 = model.encoder(x2.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "                z_pair = torch.stack([z1, z2], dim=0)  # [2, latent_dim]\n",
    "                z_list.append(z_pair.cpu())\n",
    "\n",
    "        z_pairs = torch.stack(z_list, dim=0)  # [num_pairs, 2, latent_dim]\n",
    "        z_pairs_dict[model_name] = z_pairs\n",
    "        print(f\"✅ Encoded z_pairs for {model_name}\")\n",
    "\n",
    "    return z_pairs_dict\n",
    "\n",
    "# 调用：\n",
    "z_pairs_all_models = encode_test_image_pairs(models, test_image_pairs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Q1WER8-gXOl4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "def plot_geodesics_per_vae(model_name, z_all, y_all, z_pairs, curves_list, title, out_path):\n",
    "    num_pairs = z_pairs.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    base_cmap = matplotlib.colormaps[\"tab10\"]\n",
    "    tab10_colors = base_cmap(np.arange(10))\n",
    "    background_colors = tab10_colors[7:10]\n",
    "    light_colors = [((r + 1)/2, (g + 1)/2, (b + 1)/2, 0.3) for r, g, b, _ in background_colors]\n",
    "    light_cmap = ListedColormap(light_colors)\n",
    "    mapped_labels = (y_all % 3).numpy()\n",
    "\n",
    "    ax.scatter(z_all[:, 0], z_all[:, 1], c=mapped_labels, cmap=light_cmap, s=10, alpha=0.6, zorder=1)\n",
    "\n",
    "    t_vals = torch.linspace(0, 1, 256).to(z_all.device)\n",
    "    x_all, y_all_ = [], []\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        z1, z2 = z_pairs[i, 0], z_pairs[i, 1]\n",
    "        curve_obj = curves_list[i]\n",
    "\n",
    "        if isinstance(curve_obj, torch.Tensor):\n",
    "            gamma = curve_obj.cpu()\n",
    "        else:\n",
    "            gamma = curve_obj(t_vals).detach().cpu()\n",
    "\n",
    "        ax.plot(gamma[:, 0], gamma[:, 1], linewidth=1.5, zorder=2)\n",
    "\n",
    "        # 找到最近的潜变量点，获取标签类别\n",
    "        idx1 = torch.argmin(torch.norm(z_all - z1, dim=1))\n",
    "        idx2 = torch.argmin(torch.norm(z_all - z2, dim=1))\n",
    "        label1_mod3 = int(y_all[idx1]) % 3\n",
    "        label2_mod3 = int(y_all[idx2]) % 3\n",
    "        color1 = light_cmap(label1_mod3)\n",
    "        color2 = light_cmap(label2_mod3)\n",
    "\n",
    "        ax.scatter(z1[0], z1[1], color=color1, s=30, zorder=3)\n",
    "        ax.scatter(z2[0], z2[1], color=color2, s=30, zorder=3)\n",
    "\n",
    "        ax.text(z1[0], z1[1], str(i + 1), fontsize=9, color='black', ha='center', va='center', zorder=4)\n",
    "        ax.text(z2[0], z2[1], str(i + 1), fontsize=9, color='black', ha='center', va='center', zorder=4)\n",
    "\n",
    "        x_all.extend(gamma[:, 0].tolist())\n",
    "        y_all_.extend(gamma[:, 1].tolist())\n",
    "\n",
    "    if x_all and y_all_:\n",
    "        ax.set_xlim(min(x_all) - 0.5, max(x_all) + 0.5)\n",
    "        ax.set_ylim(min(y_all_) - 0.5, max(y_all_) + 0.5)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"z1\")\n",
    "    ax.set_ylabel(\"z2\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gyoi6RXkLTB6",
    "outputId": "de13dfea-7007-4324-a612-76d7a69a9185"
   },
   "outputs": [],
   "source": [
    "# decoder 数目索引\n",
    "max_decoder_num=3\n",
    "decoder_indices = [0, max_decoder_num - 1]  # decoder=1 和 decoder=max\n",
    "decoder_nums = [1, max_decoder_num]\n",
    "\n",
    "for decoder_idx, decoder_num in zip(decoder_indices, decoder_nums):\n",
    "    for vae_idx in range(num_vaes):\n",
    "        model_name = f\"vae_d{max_decoder_num}_seed{1000 + vae_idx}\"\n",
    "        \n",
    "        # 获取潜变量和标签\n",
    "        z_all, y_all = latents_all_models[model_name]\n",
    "        \n",
    "        # 获取该模型的测试点对编码 (z1, z2)\n",
    "        z_pairs = z_pairs_all_models[model_name]  # [num_pairs, 2, 2]\n",
    "        \n",
    "        # 获取测地线曲线\n",
    "        curves_list = geodesic_curves[decoder_idx][\n",
    "            :  # 所有测试点对\n",
    "        ][vae_idx]  # 注意：内部结构是 [pair_idx][vae_idx]\n",
    "\n",
    "        # 转置结构：geodesic_curves[decoder_idx][pair_idx][vae_idx] → [pair_idx]\n",
    "        curves_per_pair = [geodesic_curves[decoder_idx][pair_idx][vae_idx] for pair_idx in range(len(z_pairs))]\n",
    "\n",
    "        # 标题和输出路径\n",
    "        title = f\"Geodesics (VAE {vae_idx}, Decoder={decoder_num})\"\n",
    "        out_path = f\"geodesic_plots/compare_d{decoder_num}_vae{vae_idx}.png\"\n",
    "\n",
    "        # 画图\n",
    "        plot_geodesics_per_vae(\n",
    "            model_name=model_name,\n",
    "            z_all=z_all,\n",
    "            y_all=y_all,\n",
    "            z_pairs=z_pairs,\n",
    "            curves_list=curves_per_pair,\n",
    "            title=title,\n",
    "            out_path=out_path\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lP4e6Ep55LGB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(\"results_geodesic\"):\n",
    "    shutil.rmtree(\"results_geodesic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCqeSyz7cPU2"
   },
   "source": [
    "## 7.3 energy log plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "GrY1hoct6gKE"
   },
   "outputs": [],
   "source": [
    "def plot_all_energy_logs(max_decoder_num, num_pairs, num_vaes, root='results_geodesic', out_root='energy_plots'):\n",
    "    for n in range(1, max_decoder_num + 1):\n",
    "        for pair_idx in range(num_pairs):\n",
    "            for m in range(num_vaes):\n",
    "                log_path = f\"{root}/decoders_{n}/pair_{pair_idx}/vae_{m}/energy_log.pt\"\n",
    "                if not os.path.exists(log_path):\n",
    "                    print(f\"❌ Missing: {log_path}\")\n",
    "                    continue\n",
    "\n",
    "                # 加载 energy_log\n",
    "                energy_log = torch.load(log_path)\n",
    "\n",
    "                # 准备输出路径\n",
    "                save_dir = f\"{out_root}/decoders_{n}/pair_{pair_idx}/vae_{m}\"\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                save_path = os.path.join(save_dir, \"energy.png\")\n",
    "\n",
    "                # 绘图\n",
    "                plt.figure()\n",
    "                plt.plot(energy_log)\n",
    "                plt.xlabel(\"Optimization Step\")\n",
    "                plt.ylabel(\"Energy\")\n",
    "                plt.title(f\"Decoders={n}, Pair={pair_idx}, VAE={m}\")\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(save_path)\n",
    "                plt.close()\n",
    "\n",
    "                print(f\"✅ Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXEbQQTS6kzM",
    "outputId": "6cd801ce-6331-4584-cd0f-731f554a19bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: energy_plots/decoders_1/pair_0/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_1/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_2/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_3/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_4/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_5/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_6/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_7/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_8/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_9/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_10/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_11/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_12/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_13/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_14/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_15/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_16/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_17/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_18/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_19/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_20/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_21/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_22/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_23/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_1/pair_24/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_0/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_1/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_2/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_3/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_4/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_5/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_6/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_7/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_8/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_9/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_10/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_11/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_12/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_13/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_14/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_15/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_16/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_17/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_18/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_19/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_20/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_21/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_22/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_23/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_2/pair_24/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_0/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_1/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_2/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_3/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_4/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_5/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_6/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_7/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_8/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_9/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_10/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_11/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_12/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_13/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_14/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_15/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_16/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_17/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_18/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_19/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_20/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_21/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_22/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_23/vae_0/energy.png\n",
      "✅ Saved: energy_plots/decoders_3/pair_24/vae_0/energy.png\n"
     ]
    }
   ],
   "source": [
    "plot_all_energy_logs(max_decoder_num=3, num_pairs=25, num_vaes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QJL_g3-9S1u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(\"results_geodesic\"):\n",
    "    shutil.rmtree(\"results_geodesic\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59KiRvyAcSmV"
   },
   "source": [
    "##7.4 geodesics plot not relevant to this task,alough helpful to task1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Dm3iOkAYzJO"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbDoZhzAcLsP"
   },
   "outputs": [],
   "source": [
    "#7.3 energy log plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIDjaq0Y2Kmw"
   },
   "source": [
    "# 8.1 Euclidean Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlwCJ3-p2So0"
   },
   "outputs": [],
   "source": [
    "def compute_all_euclidean_distances(models_dict, test_image_pairs, max_decoder_num=3, num_vaes=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    distances = []  # [decoder_num - 1][pair_idx][vae_idx]\n",
    "\n",
    "    for number_of_decoders in range(1, max_decoder_num + 1):\n",
    "        pair_results = []\n",
    "\n",
    "        for pair_idx, (x1, x2) in enumerate(test_image_pairs):\n",
    "            vae_results = []\n",
    "\n",
    "            for m in range(num_vaes):\n",
    "                model_name = f\"vae_d{max_decoder_num}_seed{1000 + m}\"\n",
    "                model = models_dict[model_name]\n",
    "                model.eval()\n",
    "\n",
    "                result_dir = f\"results_euclidean/decoders_{number_of_decoders}/pair_{pair_idx}/vae_{m}\"\n",
    "                os.makedirs(result_dir, exist_ok=True)\n",
    "                dist_path = os.path.join(result_dir, \"euclidean.pt\")\n",
    "\n",
    "                if os.path.exists(dist_path):\n",
    "                    euclidean = torch.load(dist_path,map_location=device,weights_only=False)\n",
    "                    print(f\"✅ Loaded: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        z1 = model.encoder(x1.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "                        z2 = model.encoder(x2.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
    "\n",
    "                    euclidean = torch.norm(z1 - z2, p=2).item()#这里是取了平方根的\n",
    "                    torch.save(euclidean, dist_path)\n",
    "                    print(f\"✅ Computed & saved: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
    "\n",
    "                vae_results.append(euclidean)\n",
    "\n",
    "            pair_results.append(vae_results)\n",
    "\n",
    "        distances.append(pair_results)\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcDEKDuw2Twr",
    "outputId": "d6c1ebf3-5684-4a03-a2fd-56708a72cd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Computed & saved: decoders=1, pair=0, vae=0\n",
      "✅ Computed & saved: decoders=1, pair=0, vae=1\n",
      "✅ Computed & saved: decoders=1, pair=0, vae=2\n",
      "✅ Computed & saved: decoders=1, pair=1, vae=0\n",
      "✅ Computed & saved: decoders=1, pair=1, vae=1\n",
      "✅ Computed & saved: decoders=1, pair=1, vae=2\n",
      "✅ Computed & saved: decoders=1, pair=2, vae=0\n",
      "✅ Computed & saved: decoders=1, pair=2, vae=1\n",
      "✅ Computed & saved: decoders=1, pair=2, vae=2\n",
      "✅ Computed & saved: decoders=2, pair=0, vae=0\n",
      "✅ Computed & saved: decoders=2, pair=0, vae=1\n",
      "✅ Computed & saved: decoders=2, pair=0, vae=2\n",
      "✅ Computed & saved: decoders=2, pair=1, vae=0\n",
      "✅ Computed & saved: decoders=2, pair=1, vae=1\n",
      "✅ Computed & saved: decoders=2, pair=1, vae=2\n",
      "✅ Computed & saved: decoders=2, pair=2, vae=0\n",
      "✅ Computed & saved: decoders=2, pair=2, vae=1\n",
      "✅ Computed & saved: decoders=2, pair=2, vae=2\n",
      "✅ Computed & saved: decoders=3, pair=0, vae=0\n",
      "✅ Computed & saved: decoders=3, pair=0, vae=1\n",
      "✅ Computed & saved: decoders=3, pair=0, vae=2\n",
      "✅ Computed & saved: decoders=3, pair=1, vae=0\n",
      "✅ Computed & saved: decoders=3, pair=1, vae=1\n",
      "✅ Computed & saved: decoders=3, pair=1, vae=2\n",
      "✅ Computed & saved: decoders=3, pair=2, vae=0\n",
      "✅ Computed & saved: decoders=3, pair=2, vae=1\n",
      "✅ Computed & saved: decoders=3, pair=2, vae=2\n"
     ]
    }
   ],
   "source": [
    "euclidean_distances = compute_all_euclidean_distances(\n",
    "    models_dict=models,\n",
    "    test_image_pairs=test_image_pairs,\n",
    "    max_decoder_num=3,\n",
    "    num_vaes=10\n",
    ")\n",
    "#test_image_pairs = [\n",
    "    #(all_test_x[indices[i]], all_test_x[indices[i + 1]])\n",
    "    #for i in range(0, 2 * num_pairs, 2)\n",
    "#]  还是那10个测试点对，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNmB38ASP0_p",
    "outputId": "27874a1a-a379-40b7-d8a9-b627cbbd9554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
       "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
       "  [5.820830345153809, 4.815484523773193, 5.016952991485596]],\n",
       " [[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
       "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
       "  [5.820830345153809, 4.815484523773193, 5.016952991485596]],\n",
       " [[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
       "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
       "  [5.820830345153809, 4.815484523773193, 5.016952991485596]]]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhGKPtNn9bBU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(\"results_euclidean\"):\n",
    "    shutil.rmtree(\"results_euclidean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZhZSP5R2aB_"
   },
   "source": [
    "# 8.2  compute Average Cov~num of decoders (both the geodesics and Euclidean) # i forget to take sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHBE_u-g2laX"
   },
   "outputs": [],
   "source": [
    "def compute_avg_covs_across_pairs(distances):\n",
    "    avg_covs = []\n",
    "    decoder_indices = []\n",
    "    # distances == [decoder_num - 1][pair_idx][vae_idx]\n",
    "\n",
    "    for decoder_idx, all_pairs in enumerate(distances):  # Outer loop over decoder count\n",
    "        covs = []  # covs[1]: cov_ij for the first test point, covs[2]: for the second, etc.\n",
    "\n",
    "        for vae_dists in all_pairs:  # [pair_idx][vae_idx], all_pairs[1] = first test point\n",
    "            d = np.array(vae_dists)\n",
    "            mean = np.mean(d)  # Mean across 10 VAEs\n",
    "            std = np.std(d)    # Std across 10 VAEs\n",
    "\n",
    "            if mean > 0:\n",
    "                cov = std / mean  # Compute cov_ij for the current test point\n",
    "                covs.append(cov)  # Append current test point's cov_ij to covs list\n",
    "\n",
    "        avg_cov = np.mean(covs)  # Average cov_ij over 10 test points\n",
    "        avg_covs.append(avg_cov)  # Append to avg_covs list for the current decoder count\n",
    "        decoder_indices.append(decoder_idx + 1)  # Decoder count starts from 1\n",
    "\n",
    "    return avg_covs, decoder_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1Qq9vho2pFi"
   },
   "outputs": [],
   "source": [
    "geodesic_avg_covs, decoder_counts = compute_avg_covs_across_pairs(geodesic_distances)\n",
    "euclidean_avg_covs, _ = compute_avg_covs_across_pairs(euclidean_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZc3_qVn2qtb"
   },
   "outputs": [],
   "source": [
    "def plot_and_save_avg_cov(geodesic_avg_covs, euclidean_avg_covs, decoder_counts, save_path=\"final_plots/avg_cov_vs_decoders.png\"):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(decoder_counts, geodesic_avg_covs, marker='o', label='Geodesic distance')\n",
    "    plt.plot(decoder_counts, euclidean_avg_covs, marker='o', label='Euclidean distance')\n",
    "    plt.xlabel('Number of ensemble decoders')\n",
    "    plt.ylabel('Average Coefficient of Variation (CoV)')\n",
    "    plt.title('Average CoV vs. Number of Ensemble Decoders')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "kXrPlNuUSsx1",
    "outputId": "8a8997f5-4152-42e6-8669-5c49b09ec3a5"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_535fe1b2-60a2-4af6-8470-8424c5c2b085\", \"figure2.zip\", 25957883)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_save_avg_cov(geodesic_avg_covs, euclidean_avg_covs, decoder_counts)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
